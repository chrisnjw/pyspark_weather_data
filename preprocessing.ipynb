{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a7a52b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/21 16:57:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.1\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, substring, when, hour, month, dayofyear\n",
    "from pyspark.sql.types import DoubleType, TimestampType\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GlobalHourlyWeather\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "351822f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 01001099999.csv\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000100644 0000000 0000000 00010620251 14760163177 011523\u0000 0\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ustar\u000000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000000000 0000000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\"STATION\": string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- SOURCE: string (nullable = true)\n",
      " |-- LATITUDE: string (nullable = true)\n",
      " |-- LONGITUDE: string (nullable = true)\n",
      " |-- ELEVATION: string (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- REPORT_TYPE: string (nullable = true)\n",
      " |-- CALL_SIGN: string (nullable = true)\n",
      " |-- QUALITY_CONTROL: string (nullable = true)\n",
      " |-- WND: string (nullable = true)\n",
      " |-- CIG: string (nullable = true)\n",
      " |-- VIS: string (nullable = true)\n",
      " |-- TMP: string (nullable = true)\n",
      " |-- DEW: string (nullable = true)\n",
      " |-- SLP: string (nullable = true)\n",
      " |-- AA1: string (nullable = true)\n",
      " |-- AA2: string (nullable = true)\n",
      " |-- AA3: string (nullable = true)\n",
      " |-- AJ1: string (nullable = true)\n",
      " |-- AY1: string (nullable = true)\n",
      " |-- AY2: string (nullable = true)\n",
      " |-- GA1: string (nullable = true)\n",
      " |-- GA2: string (nullable = true)\n",
      " |-- GA3: string (nullable = true)\n",
      " |-- GE1: string (nullable = true)\n",
      " |-- GF1: string (nullable = true)\n",
      " |-- IA1: string (nullable = true)\n",
      " |-- KA1: string (nullable = true)\n",
      " |-- KA2: string (nullable = true)\n",
      " |-- MA1: string (nullable = true)\n",
      " |-- MD1: string (nullable = true)\n",
      " |-- MW1: string (nullable = true)\n",
      " |-- OC1: string (nullable = true)\n",
      " |-- OD1: string (nullable = true)\n",
      " |-- SA1: string (nullable = true)\n",
      " |-- UA1: string (nullable = true)\n",
      " |-- REM: string (nullable = true)\n",
      " |-- EQD: string (nullable = true)\n",
      "\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+------+----------+----------+---------+----------------------+-----------+---------+---------------+--------------+-----------+------------+-------+-------+-------+-----------+----+----+----+----+----+----+----+----+----+----+----+-------------+-------------+---------------+----------------+----+------+---------------+----+----+----------+----------------+\n",
      "|01001099999.csv\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000100644 0000000 0000000 00010620251 14760163177 011523\u0000 0\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ustar\u000000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000000000 0000000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\"STATION\"|DATE               |SOURCE|LATITUDE  |LONGITUDE |ELEVATION|NAME                  |REPORT_TYPE|CALL_SIGN|QUALITY_CONTROL|WND           |CIG        |VIS         |TMP    |DEW    |SLP    |AA1        |AA2 |AA3 |AJ1 |AY1 |AY2 |GA1 |GA2 |GA3 |GE1 |GF1 |IA1 |KA1          |KA2          |MA1            |MD1             |MW1 |OC1   |OD1            |SA1 |UA1 |REM       |EQD             |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+------+----------+----------+---------+----------------------+-----------+---------+---------------+--------------+-----------+------------+-------+-------+-------+-----------+----+----+----+----+----+----+----+----+----+----+----+-------------+-------------+---------------+----------------+----+------+---------------+----+----+----------+----------------+\n",
      "|01001099999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |2024-01-01T00:00:00|4     |70.9333333|-8.6666667|9.0      |JAN MAYEN NOR NAVY, NO|FM-12      |99999    |V020           |318,1,N,0061,1|99999,9,9,9|999999,9,9,9|-0070,1|-0130,1|10208,1|99,9999,9,9|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|120,M,-0069,1|120,N,-0078,1|99999,9,10196,1|0,1,000,1,+999,9|NULL|0081,1|9,99,0091,1,999|NULL|NULL|SYN004BUFR|Q01  99993PRCP99|\n",
      "|01001099999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |2024-01-01T01:00:00|4     |70.9333333|-8.6666667|9.0      |JAN MAYEN NOR NAVY, NO|FM-12      |99999    |V020           |330,1,N,0051,1|99999,9,9,9|999999,9,9,9|-0065,1|-0124,1|10204,1|99,9999,9,9|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|120,M,-0064,1|120,N,-0073,1|99999,9,10192,1|8,1,007,1,+999,9|NULL|0072,1|9,99,0063,1,999|NULL|NULL|SYN004BUFR|NULL            |\n",
      "|01001099999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |2024-01-01T02:00:00|4     |70.9333333|-8.6666667|9.0      |JAN MAYEN NOR NAVY, NO|FM-12      |99999    |V020           |348,1,N,0035,1|99999,9,9,9|999999,9,9,9|-0065,1|-0113,1|10205,1|99,9999,9,9|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|120,M,-0064,1|120,N,-0070,1|99999,9,10193,1|7,1,005,1,+999,9|NULL|0076,1|9,99,0060,1,999|NULL|NULL|SYN004BUFR|NULL            |\n",
      "|01001099999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |2024-01-01T03:00:00|4     |70.9333333|-8.6666667|9.0      |JAN MAYEN NOR NAVY, NO|FM-12      |99999    |V020           |357,1,N,0019,1|99999,9,9,9|999999,9,9,9|-0064,1|-0105,1|10202,1|99,9999,9,9|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|120,M,-0063,1|120,N,-0066,1|99999,9,10190,1|7,1,006,1,+999,9|NULL|0064,1|9,99,0063,1,999|NULL|NULL|SYN004BUFR|NULL            |\n",
      "|01001099999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |2024-01-01T04:00:00|4     |70.9333333|-8.6666667|9.0      |JAN MAYEN NOR NAVY, NO|FM-12      |99999    |V020           |241,1,N,0008,1|99999,9,9,9|999999,9,9,9|-0070,1|-0106,1|10200,1|99,9999,9,9|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|120,M,-0065,1|120,N,-0073,1|99999,9,10188,1|8,1,004,1,+999,9|NULL|NULL  |9,99,0019,1,999|NULL|NULL|SYN004BUFR|NULL            |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+------+----------+----------+---------+----------------------+-----------+---------+---------------+--------------+-----------+------------+-------+-------+-------+-----------+----+----+----+----+----+----+----+----+----+----+----+-------------+-------------+---------------+----------------+----+------+---------------+----+----+----------+----------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/21 17:06:06 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "# Update this path to where your unzipped '2024' folder is\n",
    "data_path = \"2024.tar.gz\"\n",
    "\n",
    "# Load all CSVs, using the first file's header\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "# Let's see what we've got!\n",
    "df.printSchema()\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd88b06",
   "metadata": {},
   "source": [
    "## Parse and clean the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba540202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vs. Cleaned Temperature:\n",
      "+-------+-----------+\n",
      "|    TMP|temperature|\n",
      "+-------+-----------+\n",
      "|-0070,1|       -7.0|\n",
      "|-0065,1|       -6.5|\n",
      "|-0065,1|       -6.5|\n",
      "|-0064,1|       -6.4|\n",
      "|-0070,1|       -7.0|\n",
      "|-0057,1|       -5.7|\n",
      "|-0052,1|       -5.2|\n",
      "|-0057,1|       -5.7|\n",
      "|-0047,1|       -4.7|\n",
      "|-0042,1|       -4.2|\n",
      "+-------+-----------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records after cleaning TMP: 122341374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ----- THIS IS THE FIX -----\n",
    "# First, filter out any rows where TMP doesn't have a comma (or is null)\n",
    "df_with_comma = df.where(col(\"TMP\").contains(\",\"))\n",
    "# ---------------------------\n",
    "\n",
    "# 1. Split TMP into its value and quality flag\n",
    "# Now, we use df_with_comma, not df\n",
    "df_parsed = df_with_comma.withColumn(\"tmp_parts\", split(col(\"TMP\"), \",\"))\n",
    "\n",
    "# 2. Separate the value and flag into their own columns\n",
    "# This is now safe because we know a comma exists\n",
    "df_parsed = df_parsed.withColumn(\"tmp_value\", col(\"tmp_parts\")[0]) \\\n",
    "                     .withColumn(\"tmp_flag\", col(\"tmp_parts\")[1])\n",
    "\n",
    "# 3. Filter out bad data *before* scaling\n",
    "df_cleaned = df_parsed.where(\n",
    "    (col(\"tmp_value\") != \"+9999\") &\n",
    "    (col(\"tmp_flag\").isin(['1', '5']))\n",
    ")\n",
    "\n",
    "# 4. Cast to a number and apply the scaling factor (divide by 10)\n",
    "df_with_temp = df_cleaned.withColumn(\n",
    "    \"temperature\",\n",
    "    col(\"tmp_value\").cast(DoubleType()) / 10.0\n",
    ")\n",
    "\n",
    "# Let's check our work!\n",
    "print(\"Original vs. Cleaned Temperature:\")\n",
    "df_with_temp.select(\"TMP\", \"temperature\").show(10)\n",
    "\n",
    "# See how many rows we kept\n",
    "print(f\"Total records after cleaning TMP: {df_with_temp.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2668c8",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Based on that doc, your main goal is to parse DEW, SLP, and WND in the same way you parsed TMP. These columns are strong predictors of temperature.\n",
    "\n",
    "Why These Features?\n",
    "\n",
    "    DEW (Dew Point): This is the single most important predictor after time and location. The dew point is the temperature at which air becomes saturated. The difference between temperature and dew_point (called the \"spread\") directly relates to relative humidity, which is a massive factor in how much the temperature can change.\n",
    "\n",
    "    SLP (Sea Level Pressure): High pressure and low pressure systems are what cause large-scale weather and temperature changes. This is a very strong feature.\n",
    "\n",
    "    WND (Wind Observation): This column contains both wind direction and speed. Wind speed, in particular, has a strong effect on temperature (e.g., wind chill, mixing of air)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c487229",
   "metadata": {},
   "source": [
    "### Firstly, parse the date and cast the geographic column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd2d9bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema after feature engineering:\n",
      "root\n",
      " |-- 01001099999.csv\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000100644 0000000 0000000 00010620251 14760163177 011523\u0000 0\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ustar\u000000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000000000 0000000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\"STATION\": string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- SOURCE: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- elevation: double (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- REPORT_TYPE: string (nullable = true)\n",
      " |-- CALL_SIGN: string (nullable = true)\n",
      " |-- QUALITY_CONTROL: string (nullable = true)\n",
      " |-- WND: string (nullable = true)\n",
      " |-- CIG: string (nullable = true)\n",
      " |-- VIS: string (nullable = true)\n",
      " |-- TMP: string (nullable = true)\n",
      " |-- DEW: string (nullable = true)\n",
      " |-- SLP: string (nullable = true)\n",
      " |-- AA1: string (nullable = true)\n",
      " |-- AA2: string (nullable = true)\n",
      " |-- AA3: string (nullable = true)\n",
      " |-- AJ1: string (nullable = true)\n",
      " |-- AY1: string (nullable = true)\n",
      " |-- AY2: string (nullable = true)\n",
      " |-- GA1: string (nullable = true)\n",
      " |-- GA2: string (nullable = true)\n",
      " |-- GA3: string (nullable = true)\n",
      " |-- GE1: string (nullable = true)\n",
      " |-- GF1: string (nullable = true)\n",
      " |-- IA1: string (nullable = true)\n",
      " |-- KA1: string (nullable = true)\n",
      " |-- KA2: string (nullable = true)\n",
      " |-- MA1: string (nullable = true)\n",
      " |-- MD1: string (nullable = true)\n",
      " |-- MW1: string (nullable = true)\n",
      " |-- OC1: string (nullable = true)\n",
      " |-- OD1: string (nullable = true)\n",
      " |-- SA1: string (nullable = true)\n",
      " |-- UA1: string (nullable = true)\n",
      " |-- REM: string (nullable = true)\n",
      " |-- EQD: string (nullable = true)\n",
      " |-- tmp_parts: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- tmp_value: string (nullable = true)\n",
      " |-- tmp_flag: string (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day_of_year: integer (nullable = true)\n",
      "\n",
      "\n",
      "Sample of new features:\n",
      "+-------------------+----+-----+----------+---------+\n",
      "|          timestamp|hour|month|  latitude|elevation|\n",
      "+-------------------+----+-----+----------+---------+\n",
      "|2024-01-01 00:00:00|   0|    1|70.9333333|      9.0|\n",
      "|2024-01-01 01:00:00|   1|    1|70.9333333|      9.0|\n",
      "|2024-01-01 02:00:00|   2|    1|70.9333333|      9.0|\n",
      "|2024-01-01 03:00:00|   3|    1|70.9333333|      9.0|\n",
      "|2024-01-01 04:00:00|   4|    1|70.9333333|      9.0|\n",
      "|2024-01-01 05:00:00|   5|    1|70.9333333|      9.0|\n",
      "|2024-01-01 06:00:00|   6|    1|70.9333333|      9.0|\n",
      "|2024-01-01 07:00:00|   7|    1|70.9333333|      9.0|\n",
      "|2024-01-01 08:00:00|   8|    1|70.9333333|      9.0|\n",
      "|2024-01-01 09:00:00|   9|    1|70.9333333|      9.0|\n",
      "+-------------------+----+-----+----------+---------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# 1. Parse the DATE column\n",
    "df_featured = df_with_temp.withColumn(\"timestamp\", col(\"DATE\").cast(TimestampType()))\n",
    "\n",
    "# 2. Extract time-based features\n",
    "df_featured = df_featured.withColumn(\"hour\", hour(col(\"timestamp\"))) \\\n",
    "                         .withColumn(\"month\", month(col(\"timestamp\"))) \\\n",
    "                         .withColumn(\"day_of_year\", dayofyear(col(\"timestamp\")))\n",
    "\n",
    "# 3. Cast geographic features to numeric\n",
    "df_featured = df_featured.withColumn(\"latitude\", col(\"LATITUDE\").cast(DoubleType())) \\\n",
    "                         .withColumn(\"longitude\", col(\"LONGITUDE\").cast(DoubleType())) \\\n",
    "                         .withColumn(\"elevation\", col(\"ELEVATION\").cast(DoubleType()))\n",
    "\n",
    "# 4. (Recommended) Parse other weather features\n",
    "# You must repeat the \"Parse and Clean\" logic for any other\n",
    "# weather columns you want to use, like 'DEW' (Dew Point) or 'WND' (Wind).\n",
    "# Check the dataset documentation for their specific flags and scaling factors.\n",
    "\n",
    "# Let's check our new features\n",
    "print(\"Schema after feature engineering:\")\n",
    "df_featured.printSchema()\n",
    "\n",
    "print(\"\\nSample of new features:\")\n",
    "df_featured.select(\"timestamp\", \"hour\", \"month\", \"latitude\", \"elevation\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3520492",
   "metadata": {},
   "source": [
    "### Define the cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a9da9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, split\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "def clean_weather_column(input_df, col_name, missing_code, quality_flags, scale_factor):\n",
    "    \"\"\"\n",
    "    Cleans a NOAA weather column that has a 'value,flag' format.\n",
    "    \n",
    "    :param input_df: The DataFrame to transform\n",
    "    :param col_name: The name of the raw column to clean (e.g., \"DEW\", \"SLP\")\n",
    "    :param missing_code: The string code for missing values (e.g., \"+9999\", \"99999\")\n",
    "    :param quality_flags: A list of good-quality flags to keep (e.g., ['1', '5'])\n",
    "    :param scale_factor: The number to divide the value by (e.g., 10.0)\n",
    "    :return: A new DataFrame with a clean column named '<col_name>_clean'\n",
    "    \"\"\"\n",
    "    print(f\"Cleaning column: {col_name}...\")\n",
    "    \n",
    "    # 1. Filter out rows without a comma (like we did for TMP)\n",
    "    df_with_comma = input_df.where(col(col_name).contains(\",\"))\n",
    "\n",
    "    # 2. Split into value and flag\n",
    "    df_parsed = df_with_comma.withColumn(f\"{col_name}_parts\", split(col(col_name), \",\"))\n",
    "    \n",
    "    df_parsed = df_parsed.withColumn(f\"{col_name}_value\", col(f\"{col_name}_parts\")[0]) \\\n",
    "                         .withColumn(f\"{col_name}_flag\", col(f\"{col_name}_parts\")[1])\n",
    "\n",
    "    # 3. Filter out bad data\n",
    "    df_cleaned = df_parsed.where(\n",
    "        (col(f\"{col_name}_value\") != missing_code) &\n",
    "        (col(f\"{col_name}_flag\").isin(quality_flags))\n",
    "    )\n",
    "    \n",
    "    # 4. Create the final scaled, numeric column\n",
    "    clean_col_name = col_name.lower() + \"_clean\" # e.g., 'dew_clean'\n",
    "    \n",
    "    df_final = df_cleaned.withColumn(\n",
    "        clean_col_name,\n",
    "        col(f\"{col_name}_value\").cast(DoubleType()) / scale_factor\n",
    "    )\n",
    "    \n",
    "    # 5. Drop the intermediate columns\n",
    "    df_final = df_final.drop(col_name, f\"{col_name}_parts\", f\"{col_name}_value\", f\"{col_name}_flag\")\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5ff479",
   "metadata": {},
   "source": [
    "### Clean the feature DEW (Dew Point) and SLP (Sea Level Pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b726c7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning column: DEW...\n",
      "Cleaning column: SLP...\n",
      "+-----------+---------+---------+\n",
      "|temperature|dew_clean|slp_clean|\n",
      "+-----------+---------+---------+\n",
      "|       -7.0|    -13.0|   1020.8|\n",
      "|       -6.5|    -12.4|   1020.4|\n",
      "|       -6.5|    -11.3|   1020.5|\n",
      "|       -6.4|    -10.5|   1020.2|\n",
      "|       -7.0|    -10.6|   1020.0|\n",
      "|       -5.7|     -9.9|   1019.6|\n",
      "|       -5.2|     -9.5|   1019.6|\n",
      "|       -5.7|     -9.9|   1019.5|\n",
      "|       -4.7|     -8.6|   1019.2|\n",
      "|       -4.2|     -7.7|   1018.7|\n",
      "+-----------+---------+---------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# We start with df_featured from the previous step\n",
    "df_final_features = df_featured\n",
    "\n",
    "# Clean the DEW column\n",
    "# Missing code: +9999, Quality flags: '1', '5', Scale: 10.0\n",
    "df_final_features = clean_weather_column(\n",
    "    input_df=df_final_features,\n",
    "    col_name=\"DEW\",\n",
    "    missing_code=\"+9999\",\n",
    "    quality_flags=['1', '5'],\n",
    "    scale_factor=10.0\n",
    ")\n",
    "\n",
    "# Clean the SLP column\n",
    "# Missing code: 99999, Quality flags: '1', '5', Scale: 10.0\n",
    "df_final_features = clean_weather_column(\n",
    "    input_df=df_final_features,\n",
    "    col_name=\"SLP\",\n",
    "    missing_code=\"99999\",\n",
    "    quality_flags=['1', '5'],\n",
    "    scale_factor=10.0\n",
    ")\n",
    "\n",
    "# Check our new clean columns\n",
    "df_final_features.select(\"temperature\", \"dew_clean\", \"slp_clean\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63775eb6",
   "metadata": {},
   "source": [
    "### Now for the WND column\n",
    "\n",
    "The WND (Wind) column is more complex. It's not just one value and a flag. It's typically: Direction, DirectionQuality, Type, Speed, SpeedQuality\n",
    "You'll need a separate, custom-parsing logic for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "512b9ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+\n",
      "|           WND|wind_speed_clean|\n",
      "+--------------+----------------+\n",
      "|318,1,N,0061,1|             6.1|\n",
      "|330,1,N,0051,1|             5.1|\n",
      "|348,1,N,0035,1|             3.5|\n",
      "|357,1,N,0019,1|             1.9|\n",
      "|241,1,N,0008,1|             0.8|\n",
      "|076,1,N,0048,1|             4.8|\n",
      "|084,1,N,0054,1|             5.4|\n",
      "|040,1,N,0023,1|             2.3|\n",
      "|098,1,N,0057,1|             5.7|\n",
      "|086,1,N,0063,1|             6.3|\n",
      "+--------------+----------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# 1. Split WND into its 5 parts\n",
    "wnd_parts = split(col(\"WND\"), \",\")\n",
    "\n",
    "# 2. Get the Speed (index 3) and SpeedQuality (index 4)\n",
    "df_wind = df_final_features.withColumn(\"wind_speed_raw\", wnd_parts[3])\n",
    "df_wind = df_wind.withColumn(\"wind_speed_flag\", wnd_parts[4])\n",
    "\n",
    "# 3. Clean and scale it\n",
    "df_wind_cleaned = df_wind.where(\n",
    "    (col(\"wind_speed_raw\") != \"9999\") &\n",
    "    (col(\"wind_speed_flag\").isin(['1', '5']))\n",
    ")\n",
    "\n",
    "df_wind_final = df_wind_cleaned.withColumn(\n",
    "    \"wind_speed_clean\",\n",
    "    col(\"wind_speed_raw\").cast(DoubleType()) / 10.0  # Assuming 10.0 scale, check docs!\n",
    ")\n",
    "\n",
    "# See the result\n",
    "df_wind_final.select(\"WND\", \"wind_speed_clean\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2bfccc",
   "metadata": {},
   "source": [
    "## Checking after cleaning and engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a023cdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 01001099999.csv\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000100644 0000000 0000000 00010620251 14760163177 011523\u0000 0\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ustar\u000000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000000000 0000000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\"STATION\": string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- SOURCE: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- elevation: double (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- REPORT_TYPE: string (nullable = true)\n",
      " |-- CALL_SIGN: string (nullable = true)\n",
      " |-- QUALITY_CONTROL: string (nullable = true)\n",
      " |-- WND: string (nullable = true)\n",
      " |-- CIG: string (nullable = true)\n",
      " |-- VIS: string (nullable = true)\n",
      " |-- TMP: string (nullable = true)\n",
      " |-- AA1: string (nullable = true)\n",
      " |-- AA2: string (nullable = true)\n",
      " |-- AA3: string (nullable = true)\n",
      " |-- AJ1: string (nullable = true)\n",
      " |-- AY1: string (nullable = true)\n",
      " |-- AY2: string (nullable = true)\n",
      " |-- GA1: string (nullable = true)\n",
      " |-- GA2: string (nullable = true)\n",
      " |-- GA3: string (nullable = true)\n",
      " |-- GE1: string (nullable = true)\n",
      " |-- GF1: string (nullable = true)\n",
      " |-- IA1: string (nullable = true)\n",
      " |-- KA1: string (nullable = true)\n",
      " |-- KA2: string (nullable = true)\n",
      " |-- MA1: string (nullable = true)\n",
      " |-- MD1: string (nullable = true)\n",
      " |-- MW1: string (nullable = true)\n",
      " |-- OC1: string (nullable = true)\n",
      " |-- OD1: string (nullable = true)\n",
      " |-- SA1: string (nullable = true)\n",
      " |-- UA1: string (nullable = true)\n",
      " |-- REM: string (nullable = true)\n",
      " |-- EQD: string (nullable = true)\n",
      " |-- tmp_parts: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- tmp_value: string (nullable = true)\n",
      " |-- tmp_flag: string (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day_of_year: integer (nullable = true)\n",
      " |-- dew_clean: double (nullable = true)\n",
      " |-- slp_clean: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this in a new cell\n",
    "df_final_features.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c0d2243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+------------------+\n",
      "|summary|       temperature|         dew_clean|         slp_clean|          latitude|          longitude|         elevation|              hour|            month|       day_of_year|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+------------------+\n",
      "|  count|          49055736|          49055736|          49055736|          49055736|           49055736|          49055736|          49055736|         49055736|          49055736|\n",
      "|   mean|12.831891946655992| 7.024021272452314|1014.4458740646248| 32.88926715142788|-14.876760894417405|281.07311849390624|11.364602316842214|6.493168464540008| 182.8215298410771|\n",
      "| stddev|12.696444601219277|11.624523086464317| 9.060583091053223|29.368480707623316|   89.0963651980996|409.96194834192625|6.8748950403072655|3.458683880161143|105.98786817912037|\n",
      "|    min|             -81.4|             -85.6|             860.6|       -82.7666666|       -179.9833333|            -999.9|                 0|                1|                 1|\n",
      "|    max|              55.6|              36.8|            1090.0|             83.65|             179.75|            4613.0|                23|               12|               366|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check summary statistics\n",
    "\n",
    "# Define the list of all our final numeric features\n",
    "numeric_cols = [\n",
    "    \"temperature\", \n",
    "    \"dew_clean\", \n",
    "    \"slp_clean\", \n",
    "    \"latitude\", \n",
    "    \"longitude\", \n",
    "    \"elevation\", \n",
    "    \"hour\", \n",
    "    \"month\", \n",
    "    \"day_of_year\"\n",
    "    # Add 'wind_speed_clean' if you also engineered that\n",
    "]\n",
    "\n",
    "# Get the statistics for just those columns\n",
    "df_final_features.select(numeric_cols).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b8c7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+--------+---------+---------+----+-----+-----------+\n",
      "|temperature|dew_clean|slp_clean|latitude|longitude|elevation|hour|month|day_of_year|\n",
      "+-----------+---------+---------+--------+---------+---------+----+-----+-----------+\n",
      "|          0|        0|        0|       0|        0|        0|   0|    0|          0|\n",
      "+-----------+---------+---------+--------+---------+---------+----+-----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Checking for Null or Nan Value\n",
    "from pyspark.sql.functions import count, when, isnan\n",
    "\n",
    "# We'll use the same list of columns from before\n",
    "cols_to_check = numeric_cols \n",
    "\n",
    "# This command counts nulls AND NaNs for each column\n",
    "df_final_features.select([\n",
    "    count(when(col(c).isNull() | isnan(c), c)).alias(c) \n",
    "    for c in cols_to_check\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "947f4380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+----------+----------+---------+----+-----+-----------+\n",
      "|temperature|dew_clean|slp_clean|  latitude| longitude|elevation|hour|month|day_of_year|\n",
      "+-----------+---------+---------+----------+----------+---------+----+-----+-----------+\n",
      "|       -7.0|    -13.0|   1020.8|70.9333333|-8.6666667|      9.0|   0|    1|          1|\n",
      "|       -6.5|    -12.4|   1020.4|70.9333333|-8.6666667|      9.0|   1|    1|          1|\n",
      "|       -6.5|    -11.3|   1020.5|70.9333333|-8.6666667|      9.0|   2|    1|          1|\n",
      "|       -6.4|    -10.5|   1020.2|70.9333333|-8.6666667|      9.0|   3|    1|          1|\n",
      "|       -7.0|    -10.6|   1020.0|70.9333333|-8.6666667|      9.0|   4|    1|          1|\n",
      "|       -5.7|     -9.9|   1019.6|70.9333333|-8.6666667|      9.0|   5|    1|          1|\n",
      "|       -5.2|     -9.5|   1019.6|70.9333333|-8.6666667|      9.0|   6|    1|          1|\n",
      "|       -5.7|     -9.9|   1019.5|70.9333333|-8.6666667|      9.0|   7|    1|          1|\n",
      "|       -4.7|     -8.6|   1019.2|70.9333333|-8.6666667|      9.0|   8|    1|          1|\n",
      "|       -4.2|     -7.7|   1018.7|70.9333333|-8.6666667|      9.0|   9|    1|          1|\n",
      "|       -3.7|     -6.7|   1018.5|70.9333333|-8.6666667|      9.0|  10|    1|          1|\n",
      "|       -3.0|     -6.0|   1017.9|70.9333333|-8.6666667|      9.0|  11|    1|          1|\n",
      "|       -2.0|     -5.2|   1017.2|70.9333333|-8.6666667|      9.0|  12|    1|          1|\n",
      "|       -1.5|     -4.6|   1016.5|70.9333333|-8.6666667|      9.0|  13|    1|          1|\n",
      "|       -1.0|     -4.1|   1016.0|70.9333333|-8.6666667|      9.0|  14|    1|          1|\n",
      "|       -0.7|     -3.8|   1015.2|70.9333333|-8.6666667|      9.0|  15|    1|          1|\n",
      "|       -0.5|     -3.5|   1014.2|70.9333333|-8.6666667|      9.0|  16|    1|          1|\n",
      "|       -0.7|     -3.3|   1013.5|70.9333333|-8.6666667|      9.0|  17|    1|          1|\n",
      "|       -0.4|     -3.3|   1013.1|70.9333333|-8.6666667|      9.0|  18|    1|          1|\n",
      "|       -0.4|     -2.7|   1012.9|70.9333333|-8.6666667|      9.0|  19|    1|          1|\n",
      "+-----------+---------+---------+----------+----------+---------+----+-----+-----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Spot-check the final data\n",
    "df_final_features.select(numeric_cols).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a9c81e",
   "metadata": {},
   "source": [
    "### Final filter and pipeline prep\n",
    "\n",
    "Look at the describe() output for elevation:\n",
    "\n",
    "    min: -999.9\n",
    "\n",
    "This -999.9 is a sentinel value, which is just another code for \"missing data\" that the documentation didn't explicitly state (it's a common one for this dataset). A real elevation of -999.9 meters is not physically possible (the lowest point on Earth is around -430m).\n",
    "\n",
    "If we leave this in, it will completely break the StandardScaler and ruin our model.\n",
    "\n",
    "Here's the code for the next cell. This cell will:\n",
    "\n",
    "    Create our final, model-ready DataFrame (model_ready_df).\n",
    "\n",
    "    Define the Spark Pipeline for VectorAssembler and StandardScaler.\n",
    "\n",
    "    Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "814177b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original count: 49055736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count after elevation filter: 49045972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preprocessing Complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/21 18:12:50 WARN MemoryStore: Not enough space to cache rdd_90_0 in memory! (computed 1197.3 MiB so far)\n",
      "25/10/21 18:12:50 WARN BlockManager: Persisting block rdd_90_0 to disk instead.\n",
      "25/10/21 18:13:00 WARN MemoryStore: Not enough space to cache rdd_90_0 in memory! (computed 1807.1 MiB so far)\n",
      "25/10/21 18:13:01 WARN MemoryStore: Not enough space to cache rdd_90_0 in memory! (computed 1807.1 MiB so far)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set count: 34334647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/21 18:17:23 WARN MemoryStore: Not enough space to cache rdd_103_0 in memory! (computed 1197.3 MiB so far)\n",
      "25/10/21 18:17:23 WARN BlockManager: Persisting block rdd_103_0 to disk instead.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set count: 14711325\n",
      "\n",
      "Ready for modeling:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                                                                     |label|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|[-3.9380883949570795,0.020745968315379146,4.117809924285261,-6.608937344385862,-0.3804191421648169,1.5469362208613393,0.14653691809229613,0.1432076101427129]|-61.0|\n",
      "|[-3.9380883949570795,0.020745968315379146,4.117809924285261,-6.608937344385862,-0.3804191421648169,1.5469362208613393,0.14653691809229613,0.1432076101427129]|-60.9|\n",
      "|[-3.9380883949570795,0.020745968315379146,4.117809924285261,-6.557319306480147,-0.4356014221947958,1.256023131560539,0.14653691809229613,0.1432076101427129] |-60.4|\n",
      "|[-3.9380883949570795,0.020745968315379146,4.117809924285261,-6.5143042748920506,-0.4907837022247747,0.965110042259739,0.14653691809229613,0.1432076101427129]|-60.0|\n",
      "|[-3.9380883949570795,0.020745968315379146,4.117809924285261,-6.5143042748920506,-0.4907837022247747,1.110566586910139,0.14653691809229613,0.1432076101427129]|-60.1|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/21 18:17:28 WARN MemoryStore: Not enough space to cache rdd_90_0 in memory! (computed 1807.1 MiB so far)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# 1. Define our final feature and label columns\n",
    "feature_cols = [\n",
    "    \"latitude\", \n",
    "    \"longitude\", \n",
    "    \"elevation\", \n",
    "    \"dew_clean\", \n",
    "    \"slp_clean\", \n",
    "    \"hour\", \n",
    "    \"month\", \n",
    "    \"day_of_year\"\n",
    "    # Add 'wind_speed_clean' here if you also built it\n",
    "]\n",
    "\n",
    "label_col = \"temperature\"\n",
    "\n",
    "# 2. Select only these columns AND filter out the bad elevation data\n",
    "model_df = df_final_features \\\n",
    "    .select(*feature_cols, label_col) \\\n",
    "    .where(col(\"elevation\") != -999.9)\n",
    "\n",
    "print(f\"Original count: {df_final_features.count()}\")\n",
    "print(f\"Count after elevation filter: {model_df.count()}\")\n",
    "\n",
    "# 3. Create the VectorAssembler\n",
    "# This combines all feature columns into one vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# 4. Create the StandardScaler\n",
    "# This scales the \"features\" vector\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"scaledFeatures\",\n",
    "    withStd=True,\n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "# 5. Define the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(stages=[assembler, scaler])\n",
    "\n",
    "# 6. \"Fit\" the pipeline to the data\n",
    "# This learns the mean and stddev for the scaler\n",
    "preprocessing_model = preprocessing_pipeline.fit(model_df)\n",
    "\n",
    "# 7. \"Transform\" the data\n",
    "# This applies the assembly and scaling\n",
    "processed_df = preprocessing_model.transform(model_df)\n",
    "\n",
    "# 8. Select the final columns for modeling and rename label\n",
    "# We only need the scaled features and the label\n",
    "final_data = processed_df.select(\n",
    "    col(\"scaledFeatures\").alias(\"features\"),\n",
    "    col(label_col).alias(\"label\")\n",
    ")\n",
    "\n",
    "# 9. Split the dataset (70% train, 30% test)\n",
    "(train_data, test_data) = final_data.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# 10. Cache the data (important for speed!)\n",
    "train_data.cache()\n",
    "test_data.cache()\n",
    "\n",
    "print(\"\\n--- Preprocessing Complete ---\")\n",
    "print(f\"Training set count: {train_data.count()}\")\n",
    "print(f\"Test set count: {test_data.count()}\")\n",
    "print(\"\\nReady for modeling:\")\n",
    "train_data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ddb9af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
