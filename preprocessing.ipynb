{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a7a52b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/10/31 13:31:31 WARN Utils: Your hostname, Neos-MacBook-Pro.local, resolves to a loopback address: 127.0.0.1; using 172.31.115.162 instead (on interface en0)\n",
      "25/10/31 13:31:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/31 13:31:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.1\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, substring, when, hour, month, dayofyear\n",
    "from pyspark.sql.types import DoubleType, TimestampType\n",
    "from pyspark.sql.functions import radians\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GlobalHourlyWeather\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "351822f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 01001099999.csv\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000100644 0000000 0000000 00010620251 14760163177 011523\u0000 0\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ustar\u000000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000000000 0000000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\"STATION\": string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- SOURCE: string (nullable = true)\n",
      " |-- LATITUDE: string (nullable = true)\n",
      " |-- LONGITUDE: string (nullable = true)\n",
      " |-- ELEVATION: string (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- REPORT_TYPE: string (nullable = true)\n",
      " |-- CALL_SIGN: string (nullable = true)\n",
      " |-- QUALITY_CONTROL: string (nullable = true)\n",
      " |-- WND: string (nullable = true)\n",
      " |-- CIG: string (nullable = true)\n",
      " |-- VIS: string (nullable = true)\n",
      " |-- TMP: string (nullable = true)\n",
      " |-- DEW: string (nullable = true)\n",
      " |-- SLP: string (nullable = true)\n",
      " |-- AA1: string (nullable = true)\n",
      " |-- AA2: string (nullable = true)\n",
      " |-- AA3: string (nullable = true)\n",
      " |-- AJ1: string (nullable = true)\n",
      " |-- AY1: string (nullable = true)\n",
      " |-- AY2: string (nullable = true)\n",
      " |-- GA1: string (nullable = true)\n",
      " |-- GA2: string (nullable = true)\n",
      " |-- GA3: string (nullable = true)\n",
      " |-- GE1: string (nullable = true)\n",
      " |-- GF1: string (nullable = true)\n",
      " |-- IA1: string (nullable = true)\n",
      " |-- KA1: string (nullable = true)\n",
      " |-- KA2: string (nullable = true)\n",
      " |-- MA1: string (nullable = true)\n",
      " |-- MD1: string (nullable = true)\n",
      " |-- MW1: string (nullable = true)\n",
      " |-- OC1: string (nullable = true)\n",
      " |-- OD1: string (nullable = true)\n",
      " |-- SA1: string (nullable = true)\n",
      " |-- UA1: string (nullable = true)\n",
      " |-- REM: string (nullable = true)\n",
      " |-- EQD: string (nullable = true)\n",
      "\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+------+----------+----------+---------+----------------------+-----------+---------+---------------+--------------+-----------+------------+-------+-------+-------+-----------+----+----+----+----+----+----+----+----+----+----+----+-------------+-------------+---------------+----------------+----+------+---------------+----+----+----------+----------------+\n",
      "|01001099999.csv\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000100644 0000000 0000000 00010620251 14760163177 011523\u0000 0\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ustar\u000000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000000000 0000000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\"STATION\"|DATE               |SOURCE|LATITUDE  |LONGITUDE |ELEVATION|NAME                  |REPORT_TYPE|CALL_SIGN|QUALITY_CONTROL|WND           |CIG        |VIS         |TMP    |DEW    |SLP    |AA1        |AA2 |AA3 |AJ1 |AY1 |AY2 |GA1 |GA2 |GA3 |GE1 |GF1 |IA1 |KA1          |KA2          |MA1            |MD1             |MW1 |OC1   |OD1            |SA1 |UA1 |REM       |EQD             |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+------+----------+----------+---------+----------------------+-----------+---------+---------------+--------------+-----------+------------+-------+-------+-------+-----------+----+----+----+----+----+----+----+----+----+----+----+-------------+-------------+---------------+----------------+----+------+---------------+----+----+----------+----------------+\n",
      "|01001099999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |2024-01-01T00:00:00|4     |70.9333333|-8.6666667|9.0      |JAN MAYEN NOR NAVY, NO|FM-12      |99999    |V020           |318,1,N,0061,1|99999,9,9,9|999999,9,9,9|-0070,1|-0130,1|10208,1|99,9999,9,9|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|120,M,-0069,1|120,N,-0078,1|99999,9,10196,1|0,1,000,1,+999,9|NULL|0081,1|9,99,0091,1,999|NULL|NULL|SYN004BUFR|Q01  99993PRCP99|\n",
      "|01001099999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |2024-01-01T01:00:00|4     |70.9333333|-8.6666667|9.0      |JAN MAYEN NOR NAVY, NO|FM-12      |99999    |V020           |330,1,N,0051,1|99999,9,9,9|999999,9,9,9|-0065,1|-0124,1|10204,1|99,9999,9,9|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|120,M,-0064,1|120,N,-0073,1|99999,9,10192,1|8,1,007,1,+999,9|NULL|0072,1|9,99,0063,1,999|NULL|NULL|SYN004BUFR|NULL            |\n",
      "|01001099999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |2024-01-01T02:00:00|4     |70.9333333|-8.6666667|9.0      |JAN MAYEN NOR NAVY, NO|FM-12      |99999    |V020           |348,1,N,0035,1|99999,9,9,9|999999,9,9,9|-0065,1|-0113,1|10205,1|99,9999,9,9|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|120,M,-0064,1|120,N,-0070,1|99999,9,10193,1|7,1,005,1,+999,9|NULL|0076,1|9,99,0060,1,999|NULL|NULL|SYN004BUFR|NULL            |\n",
      "|01001099999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |2024-01-01T03:00:00|4     |70.9333333|-8.6666667|9.0      |JAN MAYEN NOR NAVY, NO|FM-12      |99999    |V020           |357,1,N,0019,1|99999,9,9,9|999999,9,9,9|-0064,1|-0105,1|10202,1|99,9999,9,9|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|120,M,-0063,1|120,N,-0066,1|99999,9,10190,1|7,1,006,1,+999,9|NULL|0064,1|9,99,0063,1,999|NULL|NULL|SYN004BUFR|NULL            |\n",
      "|01001099999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |2024-01-01T04:00:00|4     |70.9333333|-8.6666667|9.0      |JAN MAYEN NOR NAVY, NO|FM-12      |99999    |V020           |241,1,N,0008,1|99999,9,9,9|999999,9,9,9|-0070,1|-0106,1|10200,1|99,9999,9,9|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|120,M,-0065,1|120,N,-0073,1|99999,9,10188,1|8,1,004,1,+999,9|NULL|NULL  |9,99,0019,1,999|NULL|NULL|SYN004BUFR|NULL            |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+------+----------+----------+---------+----------------------+-----------+---------+---------------+--------------+-----------+------------+-------+-------+-------+-----------+----+----+----+----+----+----+----+----+----+----+----+-------------+-------------+---------------+----------------+----+------+---------------+----+----+----------+----------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/31 13:34:01 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "# Update this path to where your unzipped '2024' folder is\n",
    "data_path = \"2024.tar.gz\"\n",
    "\n",
    "# Load all CSVs, using the first file's header\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "# Let's see what we've got!\n",
    "df.printSchema()\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd88b06",
   "metadata": {},
   "source": [
    "## Parse and clean the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba540202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vs. Cleaned Temperature:\n",
      "+-------+-----------+\n",
      "|    TMP|temperature|\n",
      "+-------+-----------+\n",
      "|-0070,1|       -7.0|\n",
      "|-0065,1|       -6.5|\n",
      "|-0065,1|       -6.5|\n",
      "|-0064,1|       -6.4|\n",
      "|-0070,1|       -7.0|\n",
      "|-0057,1|       -5.7|\n",
      "|-0052,1|       -5.2|\n",
      "|-0057,1|       -5.7|\n",
      "|-0047,1|       -4.7|\n",
      "|-0042,1|       -4.2|\n",
      "+-------+-----------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records after cleaning TMP: 122341374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ----- THIS IS THE FIX -----\n",
    "# First, filter out any rows where TMP doesn't have a comma (or is null)\n",
    "df_with_comma = df.where(col(\"TMP\").contains(\",\"))\n",
    "# ---------------------------\n",
    "\n",
    "# 1. Split TMP into its value and quality flag\n",
    "# Now, we use df_with_comma, not df\n",
    "df_parsed = df_with_comma.withColumn(\"tmp_parts\", split(col(\"TMP\"), \",\"))\n",
    "\n",
    "# 2. Separate the value and flag into their own columns\n",
    "# This is now safe because we know a comma exists\n",
    "df_parsed = df_parsed.withColumn(\"tmp_value\", col(\"tmp_parts\")[0]) \\\n",
    "                     .withColumn(\"tmp_flag\", col(\"tmp_parts\")[1])\n",
    "\n",
    "# 3. Filter out bad data *before* scaling\n",
    "df_cleaned = df_parsed.where(\n",
    "    (col(\"tmp_value\") != \"+9999\") &\n",
    "    (col(\"tmp_flag\").isin(['1', '5']))\n",
    ")\n",
    "\n",
    "# 4. Cast to a number and apply the scaling factor (divide by 10)\n",
    "df_with_temp = df_cleaned.withColumn(\n",
    "    \"temperature\",\n",
    "    col(\"tmp_value\").cast(DoubleType()) / 10.0\n",
    ")\n",
    "\n",
    "# Let's check our work!\n",
    "print(\"Original vs. Cleaned Temperature:\")\n",
    "df_with_temp.select(\"TMP\", \"temperature\").show(10)\n",
    "\n",
    "# See how many rows we kept\n",
    "print(f\"Total records after cleaning TMP: {df_with_temp.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2668c8",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Based on that doc, your main goal is to parse DEW, SLP, and WND in the same way you parsed TMP. These columns are strong predictors of temperature.\n",
    "\n",
    "Why These Features?\n",
    "\n",
    "    DEW (Dew Point): This is the single most important predictor after time and location. The dew point is the temperature at which air becomes saturated. The difference between temperature and dew_point (called the \"spread\") directly relates to relative humidity, which is a massive factor in how much the temperature can change.\n",
    "\n",
    "    SLP (Sea Level Pressure): High pressure and low pressure systems are what cause large-scale weather and temperature changes. This is a very strong feature.\n",
    "\n",
    "    WND (Wind Observation): This column contains both wind direction and speed. Wind speed, in particular, has a strong effect on temperature (e.g., wind chill, mixing of air)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3520492",
   "metadata": {},
   "source": [
    "### Define the cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a9da9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, split\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "def clean_weather_column(input_df, col_name, missing_code, quality_flags, scale_factor):\n",
    "    \"\"\"\n",
    "    Cleans a NOAA weather column that has a 'value,flag' format.\n",
    "    \n",
    "    :param input_df: The DataFrame to transform\n",
    "    :param col_name: The name of the raw column to clean (e.g., \"DEW\", \"SLP\")\n",
    "    :param missing_code: The string code for missing values (e.g., \"+9999\", \"99999\")\n",
    "    :param quality_flags: A list of good-quality flags to keep (e.g., ['1', '5'])\n",
    "    :param scale_factor: The number to divide the value by (e.g., 10.0)\n",
    "    :return: A new DataFrame with a clean column named '<col_name>_clean'\n",
    "    \"\"\"\n",
    "    print(f\"Cleaning column: {col_name}...\")\n",
    "    \n",
    "    # 1. Filter out rows without a comma (like we did for TMP)\n",
    "    df_with_comma = input_df.where(col(col_name).contains(\",\"))\n",
    "\n",
    "    # 2. Split into value and flag\n",
    "    df_parsed = df_with_comma.withColumn(f\"{col_name}_parts\", split(col(col_name), \",\"))\n",
    "    \n",
    "    df_parsed = df_parsed.withColumn(f\"{col_name}_value\", col(f\"{col_name}_parts\")[0]) \\\n",
    "                         .withColumn(f\"{col_name}_flag\", col(f\"{col_name}_parts\")[1])\n",
    "\n",
    "    # 3. Filter out bad data\n",
    "    df_cleaned = df_parsed.where(\n",
    "        (col(f\"{col_name}_value\") != missing_code) &\n",
    "        (col(f\"{col_name}_flag\").isin(quality_flags))\n",
    "    )\n",
    "    \n",
    "    # 4. Create the final scaled, numeric column\n",
    "    clean_col_name = col_name.lower() + \"_clean\" # e.g., 'dew_clean'\n",
    "    \n",
    "    df_final = df_cleaned.withColumn(\n",
    "        clean_col_name,\n",
    "        col(f\"{col_name}_value\").cast(DoubleType()) / scale_factor\n",
    "    )\n",
    "    \n",
    "    # 5. Drop the intermediate columns\n",
    "    df_final = df_final.drop(col_name, f\"{col_name}_parts\", f\"{col_name}_value\", f\"{col_name}_flag\")\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c487229",
   "metadata": {},
   "source": [
    "### Firstly, parse the date and cast the geographic column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "427ac91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema after feature engineering (no 'month' cyclical features):\n",
      "root\n",
      " |-- 01001099999.csv\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000100644 0000000 0000000 00010620251 14760163177 011523\u0000 0\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ustar\u000000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000000000 0000000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\"STATION\": string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- SOURCE: string (nullable = true)\n",
      " |-- LATITUDE: string (nullable = true)\n",
      " |-- LONGITUDE: string (nullable = true)\n",
      " |-- elevation: double (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- REPORT_TYPE: string (nullable = true)\n",
      " |-- CALL_SIGN: string (nullable = true)\n",
      " |-- QUALITY_CONTROL: string (nullable = true)\n",
      " |-- WND: string (nullable = true)\n",
      " |-- CIG: string (nullable = true)\n",
      " |-- VIS: string (nullable = true)\n",
      " |-- TMP: string (nullable = true)\n",
      " |-- DEW: string (nullable = true)\n",
      " |-- SLP: string (nullable = true)\n",
      " |-- AA1: string (nullable = true)\n",
      " |-- AA2: string (nullable = true)\n",
      " |-- AA3: string (nullable = true)\n",
      " |-- AJ1: string (nullable = true)\n",
      " |-- AY1: string (nullable = true)\n",
      " |-- AY2: string (nullable = true)\n",
      " |-- GA1: string (nullable = true)\n",
      " |-- GA2: string (nullable = true)\n",
      " |-- GA3: string (nullable = true)\n",
      " |-- GE1: string (nullable = true)\n",
      " |-- GF1: string (nullable = true)\n",
      " |-- IA1: string (nullable = true)\n",
      " |-- KA1: string (nullable = true)\n",
      " |-- KA2: string (nullable = true)\n",
      " |-- MA1: string (nullable = true)\n",
      " |-- MD1: string (nullable = true)\n",
      " |-- MW1: string (nullable = true)\n",
      " |-- OC1: string (nullable = true)\n",
      " |-- OD1: string (nullable = true)\n",
      " |-- SA1: string (nullable = true)\n",
      " |-- UA1: string (nullable = true)\n",
      " |-- REM: string (nullable = true)\n",
      " |-- EQD: string (nullable = true)\n",
      " |-- tmp_parts: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- tmp_value: string (nullable = true)\n",
      " |-- tmp_flag: string (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day_of_year: integer (nullable = true)\n",
      " |-- hour_sin: double (nullable = true)\n",
      " |-- hour_cos: double (nullable = true)\n",
      " |-- day_sin: double (nullable = true)\n",
      " |-- day_cos: double (nullable = true)\n",
      " |-- geo_x: double (nullable = true)\n",
      " |-- geo_y: double (nullable = true)\n",
      " |-- geo_z: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove the month for feature engineering\n",
    "# Make sure these imports are at the top\n",
    "from pyspark.sql.functions import sin, cos, pi, hour, month, dayofyear, col\n",
    "from pyspark.sql.types import DoubleType, TimestampType\n",
    "\n",
    "# 1. Parse the DATE column\n",
    "df_featured = df_with_temp.withColumn(\"timestamp\", col(\"DATE\").cast(TimestampType()))\n",
    "\n",
    "# 2. Extract base time features\n",
    "# (NOTICE 'month' IS NO LONGER EXTRACTED)\n",
    "df_with_time = df_featured.withColumn(\"hour\", hour(col(\"timestamp\"))) \\\n",
    "                            .withColumn(\"day_of_year\", dayofyear(col(\"timestamp\")))\n",
    "\n",
    "# 3. Create cyclical features\n",
    "df_cyclical = df_with_time.withColumn(\"hour_sin\", sin(2 * pi() * col(\"hour\") / 24)) \\\n",
    "                           .withColumn(\"hour_cos\", cos(2 * pi() * col(\"hour\") / 24)) \\\n",
    "                           .withColumn(\"day_sin\", sin(2 * pi() * col(\"day_of_year\") / 366)) \\\n",
    "                           .withColumn(\"day_cos\", cos(2 * pi() * col(\"day_of_year\") / 366))\n",
    "\n",
    "# 4. Geographic features - Cast Elevation & Create Spherical Embedding for Lat/Lon\n",
    "df_geo = df_cyclical.withColumn(\"latitude_num\", col(\"LATITUDE\").cast(DoubleType())) \\\n",
    "                    .withColumn(\"longitude_num\", col(\"LONGITUDE\").cast(DoubleType())) \\\n",
    "                    .withColumn(\"elevation\", col(\"ELEVATION\").cast(DoubleType())) # Keep elevation as is\n",
    "\n",
    "# Convert degrees to radians\n",
    "df_geo = df_geo.withColumn(\"lat_rad\", radians(col(\"latitude_num\")))\n",
    "df_geo = df_geo.withColumn(\"lon_rad\", radians(col(\"longitude_num\")))\n",
    "\n",
    "# Convert to cartesian coordinates (x, y, z)\n",
    "df_geo = df_geo.withColumn(\"geo_x\", cos(col(\"lat_rad\")) * cos(col(\"lon_rad\")))\n",
    "df_geo = df_geo.withColumn(\"geo_y\", cos(col(\"lat_rad\")) * sin(col(\"lon_rad\")))\n",
    "df_geo = df_geo.withColumn(\"geo_z\", sin(col(\"lat_rad\")))\n",
    "\n",
    "# Drop intermediate and original lat/lon columns\n",
    "df_featured = df_geo.drop(\"latitude_num\", \"longitude_num\", \"lat_rad\", \"lon_rad\")\n",
    "\n",
    "# df_featured now has geo_x, geo_y, geo_z instead of latitude, longitude\n",
    "\n",
    "# # 5. Run your custom 'clean_weather_column' functions\n",
    "# # (e.g., for DEW and SLP)\n",
    "# df_featured = clean_weather_column(\n",
    "#     input_df=df_featured,\n",
    "#     col_name=\"DEW\",\n",
    "#     missing_code=\"+9999\",\n",
    "#     quality_flags=['1', '5'],\n",
    "#     scale_factor=10.0\n",
    "# )\n",
    "\n",
    "# df_featured = clean_weather_column(\n",
    "#     input_df=df_featured,\n",
    "#     col_name=\"SLP\",\n",
    "#     missing_code=\"99999\",\n",
    "#     quality_flags=['1', '5'],\n",
    "#     scale_factor=10.0\n",
    "# )\n",
    "\n",
    "# 6. Check our new features\n",
    "print(\"Schema after feature engineering (no 'month' cyclical features):\")\n",
    "df_featured.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd2d9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Parse the DATE column\n",
    "# df_featured = df_with_temp.withColumn(\"timestamp\", col(\"DATE\").cast(TimestampType()))\n",
    "\n",
    "# # 2. Extract time-based features\n",
    "# df_featured = df_featured.withColumn(\"hour\", hour(col(\"timestamp\"))) \\\n",
    "#                          .withColumn(\"month\", month(col(\"timestamp\"))) \\\n",
    "#                          .withColumn(\"day_of_year\", dayofyear(col(\"timestamp\")))\n",
    "\n",
    "# # 3. Cast geographic features to numeric\n",
    "# df_featured = df_featured.withColumn(\"latitude\", col(\"LATITUDE\").cast(DoubleType())) \\\n",
    "#                          .withColumn(\"longitude\", col(\"LONGITUDE\").cast(DoubleType())) \\\n",
    "#                          .withColumn(\"elevation\", col(\"ELEVATION\").cast(DoubleType()))\n",
    "\n",
    "# # 4. (Recommended) Parse other weather features\n",
    "# # You must repeat the \"Parse and Clean\" logic for any other\n",
    "# # weather columns you want to use, like 'DEW' (Dew Point) or 'WND' (Wind).\n",
    "# # Check the dataset documentation for their specific flags and scaling factors.\n",
    "\n",
    "# # Let's check our new features\n",
    "# print(\"Schema after feature engineering:\")\n",
    "# df_featured.printSchema()\n",
    "\n",
    "# print(\"\\nSample of new features:\")\n",
    "# df_featured.select(\"timestamp\", \"hour\", \"month\", \"latitude\", \"elevation\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5ff479",
   "metadata": {},
   "source": [
    "### Clean the feature DEW (Dew Point) and SLP (Sea Level Pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b726c7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning column: DEW...\n",
      "Cleaning column: SLP...\n",
      "+-----------+---------+---------+\n",
      "|temperature|dew_clean|slp_clean|\n",
      "+-----------+---------+---------+\n",
      "|       -7.0|    -13.0|   1020.8|\n",
      "|       -6.5|    -12.4|   1020.4|\n",
      "|       -6.5|    -11.3|   1020.5|\n",
      "|       -6.4|    -10.5|   1020.2|\n",
      "|       -7.0|    -10.6|   1020.0|\n",
      "|       -5.7|     -9.9|   1019.6|\n",
      "|       -5.2|     -9.5|   1019.6|\n",
      "|       -5.7|     -9.9|   1019.5|\n",
      "|       -4.7|     -8.6|   1019.2|\n",
      "|       -4.2|     -7.7|   1018.7|\n",
      "+-----------+---------+---------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# We start with df_featured from the previous step\n",
    "df_final_features = df_featured\n",
    "\n",
    "# Clean the DEW column\n",
    "# Missing code: +9999, Quality flags: '1', '5', Scale: 10.0\n",
    "df_final_features = clean_weather_column(\n",
    "    input_df=df_final_features,\n",
    "    col_name=\"DEW\",\n",
    "    missing_code=\"+9999\",\n",
    "    quality_flags=['1', '5'],\n",
    "    scale_factor=10.0\n",
    ")\n",
    "\n",
    "# Clean the SLP column\n",
    "# Missing code: 99999, Quality flags: '1', '5', Scale: 10.0\n",
    "df_final_features = clean_weather_column(\n",
    "    input_df=df_final_features,\n",
    "    col_name=\"SLP\",\n",
    "    missing_code=\"99999\",\n",
    "    quality_flags=['1', '5'],\n",
    "    scale_factor=10.0\n",
    ")\n",
    "\n",
    "# Check our new clean columns\n",
    "df_final_features.select(\"temperature\", \"dew_clean\", \"slp_clean\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63775eb6",
   "metadata": {},
   "source": [
    "### Now for the WND column\n",
    "\n",
    "The WND (Wind) column is more complex. It's not just one value and a flag. It's typically: Direction, DirectionQuality, Type, Speed, SpeedQuality\n",
    "You'll need a separate, custom-parsing logic for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "512b9ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+\n",
      "|           WND|wind_speed_clean|\n",
      "+--------------+----------------+\n",
      "|318,1,N,0061,1|             6.1|\n",
      "|330,1,N,0051,1|             5.1|\n",
      "|348,1,N,0035,1|             3.5|\n",
      "|357,1,N,0019,1|             1.9|\n",
      "|241,1,N,0008,1|             0.8|\n",
      "|076,1,N,0048,1|             4.8|\n",
      "|084,1,N,0054,1|             5.4|\n",
      "|040,1,N,0023,1|             2.3|\n",
      "|098,1,N,0057,1|             5.7|\n",
      "|086,1,N,0063,1|             6.3|\n",
      "+--------------+----------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# 1. Split WND into its 5 parts\n",
    "wnd_parts = split(col(\"WND\"), \",\")\n",
    "\n",
    "# 2. Get the Speed (index 3) and SpeedQuality (index 4)\n",
    "df_wind = df_final_features.withColumn(\"wind_speed_raw\", wnd_parts[3])\n",
    "df_wind = df_wind.withColumn(\"wind_speed_flag\", wnd_parts[4])\n",
    "\n",
    "# 3. Clean and scale it\n",
    "df_wind_cleaned = df_wind.where(\n",
    "    (col(\"wind_speed_raw\") != \"9999\") &\n",
    "    (col(\"wind_speed_flag\").isin(['1', '5']))\n",
    ")\n",
    "\n",
    "df_wind_final = df_wind_cleaned.withColumn(\n",
    "    \"wind_speed_clean\",\n",
    "    col(\"wind_speed_raw\").cast(DoubleType()) / 10.0  # Assuming 10.0 scale, check docs!\n",
    ")\n",
    "\n",
    "# See the result\n",
    "df_wind_final.select(\"WND\", \"wind_speed_clean\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3db31a",
   "metadata": {},
   "source": [
    "### CIG and VIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "299b1daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing CIG and VIS...\n",
      "Finished parsing CIG, VIS.\n",
      "+----------------+--------------------+---------------------+\n",
      "|wind_speed_clean|ceiling_height_clean|visibility_dist_clean|\n",
      "+----------------+--------------------+---------------------+\n",
      "|             6.8|               600.0|              25000.0|\n",
      "|             8.0|               600.0|              25000.0|\n",
      "|             5.9|               300.0|              10000.0|\n",
      "|             4.4|               300.0|              10000.0|\n",
      "|             3.2|               300.0|              10000.0|\n",
      "+----------------+--------------------+---------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, split\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Make sure the input DataFrame name matches the output of the WND cell\n",
    "df_feat = df_wind_final \n",
    "\n",
    "print(\"Parsing CIG and VIS...\")\n",
    "\n",
    "# --- Parse CIG (cloud ceiling height) - 1st value ---\n",
    "# Filter, split, extract height (index 0) & flag (index 1)\n",
    "df_cig = df_feat.where(col(\"CIG\").isNotNull() & col(\"CIG\").contains(\",\"))\n",
    "df_cig = (\n",
    "    df_cig.withColumn(\"cig_parts\", split(col(\"CIG\"), \",\"))\n",
    "    .withColumn(\"cig_value\", col(\"cig_parts\").getItem(0)) # Use getItem for safety\n",
    "    .withColumn(\"cig_flag\", col(\"cig_parts\").getItem(1)) # Use getItem for safety\n",
    ")\n",
    "# Filter missing (\"99999\") and bad quality flags (assuming '1', '5')\n",
    "df_cig = df_cig.where(\n",
    "    (col(\"cig_value\") != \"99999\") & (col(\"cig_flag\").isin([\"1\", \"5\"])) # Verify flags\n",
    ")\n",
    "# Cast height (assuming no scaling needed)\n",
    "df_feat = df_cig.withColumn(\"ceiling_height_clean\", col(\"cig_value\").cast(DoubleType()))\n",
    "df_feat = df_feat.drop(\"cig_parts\", \"cig_value\", \"cig_flag\", \"CIG\")\n",
    "\n",
    "\n",
    "# --- Parse VIS (horizontal visibility) - 1st value ---\n",
    "# Filter, split, extract distance (index 0) & flag (index 1)\n",
    "df_vis = df_feat.where(col(\"VIS\").isNotNull() & col(\"VIS\").contains(\",\"))\n",
    "df_vis = (\n",
    "    df_vis.withColumn(\"vis_parts\", split(col(\"VIS\"), \",\"))\n",
    "    .withColumn(\"vis_value\", col(\"vis_parts\").getItem(0)) # Use getItem\n",
    "    .withColumn(\"vis_flag\", col(\"vis_parts\").getItem(1)) # Use getItem\n",
    ")\n",
    "# Filter missing (\"999999\") and bad quality flags (assuming '1', '5')\n",
    "df_vis = df_vis.where(\n",
    "    (col(\"vis_value\") != \"999999\") & (col(\"vis_flag\").isin([\"1\", \"5\"])) # Verify flags\n",
    ")\n",
    "# Cast distance (assuming no scaling needed)\n",
    "df_feat = df_vis.withColumn(\"visibility_dist_clean\", col(\"vis_value\").cast(DoubleType()))\n",
    "df_feat = df_feat.drop(\"vis_parts\", \"vis_value\", \"vis_flag\", \"VIS\")\n",
    "\n",
    "# Rename the final DataFrame to match what subsequent cells expect\n",
    "df_final_features = df_feat \n",
    "\n",
    "print(\"Finished parsing CIG, VIS.\")\n",
    "df_final_features.select(\"wind_speed_clean\", \"ceiling_height_clean\", \"visibility_dist_clean\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2bfccc",
   "metadata": {},
   "source": [
    "## Checking after cleaning and engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a023cdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 01001099999.csv\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000100644 0000000 0000000 00010620251 14760163177 011523\u0000 0\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ustar\u000000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00000000000 0000000 \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\"STATION\": string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- SOURCE: string (nullable = true)\n",
      " |-- LATITUDE: string (nullable = true)\n",
      " |-- LONGITUDE: string (nullable = true)\n",
      " |-- elevation: double (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- REPORT_TYPE: string (nullable = true)\n",
      " |-- CALL_SIGN: string (nullable = true)\n",
      " |-- QUALITY_CONTROL: string (nullable = true)\n",
      " |-- WND: string (nullable = true)\n",
      " |-- TMP: string (nullable = true)\n",
      " |-- AA1: string (nullable = true)\n",
      " |-- AA2: string (nullable = true)\n",
      " |-- AA3: string (nullable = true)\n",
      " |-- AJ1: string (nullable = true)\n",
      " |-- AY1: string (nullable = true)\n",
      " |-- AY2: string (nullable = true)\n",
      " |-- GA1: string (nullable = true)\n",
      " |-- GA2: string (nullable = true)\n",
      " |-- GA3: string (nullable = true)\n",
      " |-- GE1: string (nullable = true)\n",
      " |-- GF1: string (nullable = true)\n",
      " |-- IA1: string (nullable = true)\n",
      " |-- KA1: string (nullable = true)\n",
      " |-- KA2: string (nullable = true)\n",
      " |-- MA1: string (nullable = true)\n",
      " |-- MD1: string (nullable = true)\n",
      " |-- MW1: string (nullable = true)\n",
      " |-- OC1: string (nullable = true)\n",
      " |-- OD1: string (nullable = true)\n",
      " |-- SA1: string (nullable = true)\n",
      " |-- UA1: string (nullable = true)\n",
      " |-- REM: string (nullable = true)\n",
      " |-- EQD: string (nullable = true)\n",
      " |-- tmp_parts: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- tmp_value: string (nullable = true)\n",
      " |-- tmp_flag: string (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day_of_year: integer (nullable = true)\n",
      " |-- hour_sin: double (nullable = true)\n",
      " |-- hour_cos: double (nullable = true)\n",
      " |-- day_sin: double (nullable = true)\n",
      " |-- day_cos: double (nullable = true)\n",
      " |-- geo_x: double (nullable = true)\n",
      " |-- geo_y: double (nullable = true)\n",
      " |-- geo_z: double (nullable = true)\n",
      " |-- dew_clean: double (nullable = true)\n",
      " |-- slp_clean: double (nullable = true)\n",
      " |-- wind_speed_raw: string (nullable = true)\n",
      " |-- wind_speed_flag: string (nullable = true)\n",
      " |-- wind_speed_clean: double (nullable = true)\n",
      " |-- ceiling_height_clean: double (nullable = true)\n",
      " |-- visibility_dist_clean: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this in a new cell\n",
    "df_final_features.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c0d2243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking statistics for new features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+--------------------+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|summary|       temperature|         elevation|              geo_x|              geo_y|              geo_z|         dew_clean|         slp_clean|  wind_speed_clean|ceiling_height_clean|visibility_dist_clean|            hour_sin|            hour_cos|             day_sin|             day_cos|\n",
      "+-------+------------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+--------------------+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  count|          21538227|          21538227|           21538227|           21538227|           21538227|          21538227|          21538227|          21538227|            21538227|             21538227|            21538227|            21538227|            21538227|            21538227|\n",
      "|   mean|13.090614092737242|299.92139828325696|0.07631937233583985|-0.3646051645604999| 0.6059294726690023|7.0640263982721025|1014.0976344334077|3.4606662752966666|  11985.548413989694|   16984.097199458432|-0.00595005063331...|-0.02553616274651...|-0.00771283014074...|0.002647069556172437|\n",
      "| stddev|12.555208429112774|434.77386327978434|0.38102925131986115| 0.5150920597879675| 0.2891103665609948|11.574788299090562|  8.77682669311074|2.7223271344883835|  10218.630500631465|   11016.238850518099|  0.7071190459694611|  0.7066082383571344|  0.7050357896690882|  0.7091248740423236|\n",
      "|    min|             -79.0|            -999.9|-0.9972871566238631|-0.9999578709299363|-0.9797503501713428|             -83.0|             860.6|               0.0|                 0.0|                  0.0|                -1.0|                -1.0| -0.9999631612477099|                -1.0|\n",
      "|    max|              52.4|            4535.0| 0.9958732265518964| 0.9915786920580905| 0.9914853139185485|              36.7|            1088.8|              40.0|             22000.0|             144841.0|                 1.0|                 1.0|  0.9999631612477099|                 1.0|\n",
      "+-------+------------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+--------------------+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 1. Define the list of all our final numeric features\n",
    "# (We check the sin/cos features, not the originals)\n",
    "numeric_cols = [\n",
    "    # Target Variable\n",
    "    \"temperature\", \n",
    "    # Geographic Features (New)\n",
    "    \"elevation\", \n",
    "    \"geo_x\", \"geo_y\", \"geo_z\", \n",
    "    # Weather Features (Original + New)\n",
    "    \"dew_clean\", \n",
    "    \"slp_clean\", \n",
    "    \"wind_speed_clean\",\n",
    "    \"ceiling_height_clean\",\n",
    "    \"visibility_dist_clean\",\n",
    "    # Time Features (Cyclical)\n",
    "    \"hour_sin\", \"hour_cos\",\n",
    "    \"day_sin\", \"day_cos\"\n",
    "]\n",
    "\n",
    "# 2. Get the statistics for just those columns\n",
    "print(\"Checking statistics for new features:\")\n",
    "df_final_features.select(numeric_cols).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2762d16",
   "metadata": {},
   "source": [
    "### Checking for both `NULL` and `NaN` value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b8c7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----+-----+-----+---------+---------+----------------+--------------------+---------------------+--------+--------+-------+-------+\n",
      "|temperature|elevation|geo_x|geo_y|geo_z|dew_clean|slp_clean|wind_speed_clean|ceiling_height_clean|visibility_dist_clean|hour_sin|hour_cos|day_sin|day_cos|\n",
      "+-----------+---------+-----+-----+-----+---------+---------+----------------+--------------------+---------------------+--------+--------+-------+-------+\n",
      "|          0|        0|    0|    0|    0|        0|        0|               0|                   0|                    0|       0|       0|      0|      0|\n",
      "+-----------+---------+-----+-----+-----+---------+---------+----------------+--------------------+---------------------+--------+--------+-------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Checking for Null or Nan Value\n",
    "from pyspark.sql.functions import count, when, isnan\n",
    "\n",
    "# We'll use the same list of columns from before\n",
    "cols_to_check = numeric_cols \n",
    "\n",
    "# This command counts nulls AND NaNs for each column\n",
    "df_final_features.select([\n",
    "    count(when(col(c).isNull() | isnan(c), c)).alias(c) \n",
    "    for c in cols_to_check\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "947f4380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------------------+--------------------+-----------------+---------+---------+----------------+--------------------+---------------------+--------------------+--------------------+--------------------+------------------+\n",
      "|temperature|elevation|             geo_x|               geo_y|            geo_z|dew_clean|slp_clean|wind_speed_clean|ceiling_height_clean|visibility_dist_clean|            hour_sin|            hour_cos|             day_sin|           day_cos|\n",
      "+-----------+---------+------------------+--------------------+-----------------+---------+---------+----------------+--------------------+---------------------+--------------------+--------------------+--------------------+------------------+\n",
      "|       -2.0|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -5.2|   1017.2|             6.8|               600.0|              25000.0|1.224646799147353...|                -1.0| 0.01716632975470737|0.9998526477050269|\n",
      "|       -0.7|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -3.8|   1015.2|             8.0|               600.0|              25000.0| -0.7071067811865471| -0.7071067811865479| 0.01716632975470737|0.9998526477050269|\n",
      "|        0.6|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -0.4|   1007.2|             5.9|               300.0|              10000.0|                 1.0|6.123233995736766...|0.034327600513243496|0.9994106342455052|\n",
      "|        0.6|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -0.4|   1006.8|             4.4|               300.0|              10000.0|  0.7071067811865476| -0.7071067811865475|0.034327600513243496|0.9994106342455052|\n",
      "|        0.7|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -0.6|   1006.4|             3.2|               300.0|              10000.0|1.224646799147353...|                -1.0|0.034327600513243496|0.9994106342455052|\n",
      "|        1.0|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -0.8|   1006.0|             1.2|               300.0|              10000.0| -0.7071067811865471| -0.7071067811865479|0.034327600513243496|0.9994106342455052|\n",
      "|       -1.1|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -3.1|   1006.4|             1.0|             22000.0|              25000.0|  0.7071067811865476| -0.7071067811865475| 0.05147875477034653|0.9986740898848305|\n",
      "|       -1.2|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -2.5|   1007.1|             6.3|             22000.0|              30000.0| -0.7071067811865471| -0.7071067811865479| 0.05147875477034653|0.9986740898848305|\n",
      "|       -7.0|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -9.6|   1010.5|             8.5|               300.0|              12000.0|                 1.0|6.123233995736766...| 0.06861473800213404|0.9976432316860063|\n",
      "|       -8.5|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|    -11.5|   1011.0|            11.5|               300.0|              10000.0|  0.7071067811865476| -0.7071067811865475| 0.06861473800213404|0.9976432316860063|\n",
      "|       -9.2|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|    -13.3|   1011.3|             8.0|               300.0|              14000.0|1.224646799147353...|                -1.0| 0.06861473800213404|0.9976432316860063|\n",
      "|       -8.4|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|    -11.2|   1011.1|             7.1|               300.0|              12000.0| -0.7071067811865471| -0.7071067811865479| 0.06861473800213404|0.9976432316860063|\n",
      "|       -3.2|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -5.8|   1009.1|             5.5|               300.0|              11000.0|                 1.0|6.123233995736766...| 0.08573050015569435|0.9963183634476755|\n",
      "|       -4.7|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -6.3|   1009.3|             8.0|               200.0|               9000.0|  0.7071067811865476| -0.7071067811865475| 0.08573050015569435|0.9963183634476755|\n",
      "|       -6.5|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -8.2|   1009.7|             9.8|               300.0|              14000.0|1.224646799147353...|                -1.0| 0.08573050015569435|0.9963183634476755|\n",
      "|       -8.2|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|    -11.0|   1010.0|            10.4|               300.0|              25000.0| -0.7071067811865471| -0.7071067811865479| 0.08573050015569435|0.9963183634476755|\n",
      "|       -7.0|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -9.0|   1014.3|             2.8|               300.0|               6000.0|                 1.0|6.123233995736766...|  0.1028209971373604|0.9946998756145891|\n",
      "|       -6.2|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -8.0|   1015.2|             0.3|               300.0|              20000.0|  0.7071067811865476| -0.7071067811865475|  0.1028209971373604|0.9946998756145891|\n",
      "|       -6.0|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -7.9|   1015.9|             1.4|               300.0|              20000.0|1.224646799147353...|                -1.0|  0.1028209971373604|0.9946998756145891|\n",
      "|       -0.7|      9.0|0.3229381072207145|-0.04922421478100504|0.945139119698204|     -1.6|   1020.4|             4.4|               200.0|               3000.0|1.224646799147353...|                -1.0| 0.11988119229922722|  0.99278824516254|\n",
      "+-----------+---------+------------------+--------------------+-----------------+---------+---------+----------------+--------------------+---------------------+--------------------+--------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Spot-check the final data\n",
    "df_final_features.select(numeric_cols).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f651c2",
   "metadata": {},
   "source": [
    "## Exploratory data analysis (EDA) \n",
    "\n",
    "Using a heatmap for understanding of the relationships between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f00f7091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling data for heatmap...\n",
      "Converting sample to Pandas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size for heatmap: 21352 rows\n",
      "Calculating correlation matrix...\n",
      "Plotting Correlation Heatmap:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd # Ensure pandas is imported\n",
    "\n",
    "# 1. Define the final list of columns for correlation \n",
    "#    (including target and ALL final features)\n",
    "numeric_cols = [\n",
    "    # Target Variable\n",
    "    \"temperature\", \n",
    "    # Geographic Features (New)\n",
    "    \"elevation\", \n",
    "    \"geo_x\", \"geo_y\", \"geo_z\", \n",
    "    # Weather Features (Original + New)\n",
    "    \"dew_clean\", \n",
    "    \"slp_clean\", \n",
    "    \"wind_speed_clean\", \n",
    "    \"ceiling_height_clean\", \n",
    "    \"visibility_dist_clean\", \n",
    "    # Time Features (Cyclical)\n",
    "    \"hour_sin\", \"hour_cos\",\n",
    "    \"day_sin\", \"day_cos\"\n",
    "]\n",
    "\n",
    "# 2. Select ONLY these columns and filter bad elevation data\n",
    "#    Make sure df_final_features is the correct DataFrame name after parsing WND/CIG/VIS\n",
    "df_for_corr = df_final_features.where(col(\"elevation\") != -999.9) \\\n",
    "                               .select(numeric_cols)\n",
    "\n",
    "# 3. Take a small, random sample (e.g., 0.1% = 0.001)\n",
    "print(\"Sampling data for heatmap...\")\n",
    "sample_df = df_for_corr.sample(withReplacement=False, fraction=0.001, seed=42)\n",
    "\n",
    "# 4. Convert the sample to Pandas\n",
    "print(\"Converting sample to Pandas...\")\n",
    "pandas_df = sample_df.toPandas()\n",
    "print(f\"Sample size for heatmap: {len(pandas_df)} rows\")\n",
    "\n",
    "# 5. Calculate the Pearson correlation matrix\n",
    "print(\"Calculating correlation matrix...\")\n",
    "corr_matrix = pandas_df.corr()\n",
    "\n",
    "# 6. Plot the heatmap (ONLY ONCE)\n",
    "print(\"Plotting Correlation Heatmap:\")\n",
    "plt.figure(figsize=(14, 12)) # Slightly larger figure for more features\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", annot_kws={\"size\": 8}) # Adjust font size if needed\n",
    "plt.title(\"Correlation Heatmap of Features\") # Add a title\n",
    "plt.show() # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27dcc6e",
   "metadata": {},
   "source": [
    "Correlation Heatmap Analysis\n",
    "\n",
    "Here's a breakdown of the key insights from the heatmap:\n",
    "\n",
    "1. Strongest Predictors (Temperature Row)\n",
    "\n",
    "    dew_clean (0.88): A very strong positive correlation (bright red). This is the most powerful single predictor of temperature, which makes physical sense.\n",
    "\n",
    "    day_cos (-0.44): The strongest seasonal feature. The negative correlation is correctit means that as day_cos moves from +1 (winter) to -1 (summer), the temperature increases.\n",
    "\n",
    "    latitude (-0.40): A moderate negative correlation. As latitude increases (moving north), the temperature tends to drop.\n",
    "\n",
    "2. No Multicollinearity\n",
    "\n",
    "    There are no bright red (> 0.9) or dark blue (< -0.9) squares between any two predictor features.\n",
    "\n",
    "    Conclusion: This is great news. It means all your features are providing unique information without being redundant.\n",
    "\n",
    "3. Cyclical Encoding is Correct\n",
    "\n",
    "    The correlation between hour_sin and hour_cos is 0.00.\n",
    "\n",
    "    The correlation between day_sin and day_cos is 0.00.\n",
    "\n",
    "    Conclusion: This is the mathematical proof that the sine/cosine encoding was done correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a9c81e",
   "metadata": {},
   "source": [
    "### Final filter and pipeline prep\n",
    "\n",
    "Look at the describe() output for elevation:\n",
    "\n",
    "    min: -999.9\n",
    "\n",
    "This -999.9 is a sentinel value, which is just another code for \"missing data\" that the documentation didn't explicitly state (it's a common one for this dataset). A real elevation of -999.9 meters is not physically possible (the lowest point on Earth is around -430m).\n",
    "\n",
    "If we leave this in, it will completely break the StandardScaler and ruin our model.\n",
    "\n",
    "Here's the code for the next cell. This cell will:\n",
    "\n",
    "    Create our final, model-ready DataFrame (model_ready_df).\n",
    "\n",
    "    Define the Spark Pipeline for VectorAssembler and StandardScaler.\n",
    "\n",
    "    Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "814177b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original count: 21538227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count after elevation filter: 21532405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preprocessing Complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/31 14:03:04 WARN MemoryStore: Not enough space to cache rdd_88_0 in memory! (computed 185.4 MiB so far)\n",
      "25/10/31 14:03:04 WARN BlockManager: Persisting block rdd_88_0 to disk instead.\n",
      "25/10/31 14:03:10 WARN MemoryStore: Not enough space to cache rdd_88_0 in memory! (computed 1560.1 MiB so far)\n",
      "25/10/31 14:03:11 WARN MemoryStore: Not enough space to cache rdd_88_0 in memory! (computed 1560.1 MiB so far)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set count: 15077489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/31 14:07:28 WARN MemoryStore: Not enough space to cache rdd_101_0 in memory! (computed 185.4 MiB so far)\n",
      "25/10/31 14:07:28 WARN BlockManager: Persisting block rdd_101_0 to disk instead.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set count: 6454916\n",
      "\n",
      "Ready for modeling:\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                                                                                                                                                                      |label|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|[-1.4972657805452423,1.631035074845793,1.6749103499281888,-0.3131222314888888,-0.575450685557215,0.9457301502146755,-0.50008611335208,0.9799218414807638,-0.7250080723401121,0.008477707939080013,-1.3790811431669723,-0.3502863958491905,1.3599176275370317] |21.0 |\n",
      "|[-1.4972657805452423,1.631035074845793,1.6749103499281888,-0.3131222314888888,-0.41992443955032815,1.1963831624924737,-1.2715076401765055,0.9799218414807638,-0.9065596076493685,1.42266212387099,0.03613539828024391,-0.32668774544969126,1.3658816862256635]|11.2 |\n",
      "|[-1.4972657805452423,1.631035074845793,1.6749103499281888,-0.3131222314888888,-0.21255611154114573,0.9457301502146755,-0.50008611335208,0.9799218414807638,-0.8157838399947402,1.42266212387099,0.03613539828024391,-0.7707351360925734,1.1729417928639592]   |14.4 |\n",
      "|[-1.4972657805452423,1.631035074845793,1.6749103499281888,-0.3131222314888888,-0.06567021253464148,0.740650412896476,-0.50008611335208,0.9799218414807638,-0.9065596076493685,1.0084570982928707,-0.9645738150244552,-0.06208404024380781,1.4045448492772226] |20.2 |\n",
      "|[-1.4972657805452423,1.631035074845793,1.6749103499281888,-0.3131222314888888,0.003452563468419338,0.8431902815555758,-0.50008611335208,0.9799218414807638,-0.8157838399947402,1.0084570982928707,-0.9645738150244552,-0.037757323800533364,1.40558351290915] |20.4 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/31 14:07:32 WARN MemoryStore: Not enough space to cache rdd_88_0 in memory! (computed 1560.1 MiB so far)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# 1. Define our final feature and label columns\n",
    "feature_cols = [\n",
    "    # Geographic features (New Embedding + Elevation)\n",
    "    \"elevation\", \n",
    "    \"geo_x\", \"geo_y\", \"geo_z\", \n",
    "    # Weather features (Original + New Parsed)\n",
    "    \"dew_clean\", \n",
    "    \"slp_clean\", \n",
    "    \"wind_speed_clean\",\n",
    "    \"ceiling_height_clean\",\n",
    "    \"visibility_dist_clean\",\n",
    "    # Time features (Cyclical)\n",
    "    \"hour_sin\", \"hour_cos\",\n",
    "    \"day_sin\", \"day_cos\"\n",
    "]\n",
    "\n",
    "label_col = \"temperature\"\n",
    "\n",
    "# 2. Select only these columns AND filter out the bad elevation data\n",
    "model_df = df_final_features \\\n",
    "    .select(*feature_cols, label_col) \\\n",
    "    .where(col(\"elevation\") != -999.9)\n",
    "\n",
    "print(f\"Original count: {df_final_features.count()}\")\n",
    "print(f\"Count after elevation filter: {model_df.count()}\")\n",
    "\n",
    "# 3. Create the VectorAssembler\n",
    "# This combines all feature columns into one vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# 4. Create the StandardScaler\n",
    "# This scales the \"features\" vector\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"scaledFeatures\",\n",
    "    withStd=True,\n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "# 5. Define the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(stages=[assembler, scaler])\n",
    "\n",
    "# 6. \"Fit\" the pipeline to the data\n",
    "# This learns the mean and stddev for the scaler\n",
    "preprocessing_model = preprocessing_pipeline.fit(model_df)\n",
    "\n",
    "# 7. \"Transform\" the data\n",
    "# This applies the assembly and scaling\n",
    "processed_df = preprocessing_model.transform(model_df)\n",
    "\n",
    "# 8. Select the final columns for modeling and rename label\n",
    "# We only need the scaled features and the label\n",
    "final_data = processed_df.select(\n",
    "    col(\"scaledFeatures\").alias(\"features\"),\n",
    "    col(label_col).alias(\"label\")\n",
    ")\n",
    "\n",
    "# 9. Split the dataset (70% train, 30% test)\n",
    "(train_data, test_data) = final_data.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# 10. Cache the data (important for speed!)\n",
    "train_data.cache()\n",
    "test_data.cache()\n",
    "\n",
    "print(\"\\n--- Preprocessing Complete ---\")\n",
    "print(f\"Training set count: {train_data.count()}\")\n",
    "print(f\"Test set count: {test_data.count()}\")\n",
    "print(\"\\nReady for modeling:\")\n",
    "train_data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c4023d",
   "metadata": {},
   "source": [
    "### Baseline Model: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12ddb9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/31 14:07:32 WARN Instrumentation: [2e0e8c02] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/31 14:07:33 WARN MemoryStore: Not enough space to cache rdd_88_0 in memory! (computed 1560.1 MiB so far)\n",
      "25/10/31 14:07:33 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/10/31 14:07:39 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "25/10/31 14:07:40 WARN MemoryStore: Not enough space to cache rdd_88_0 in memory! (computed 1560.1 MiB so far)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Linear Regression Results ---\n",
      "Root Mean Squared Error (RMSE) on test data = 5.037770531212898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (R2) on test data = 0.8390510789333632\n",
      "\n",
      "Sample predictions:\n",
      "+-----+------------------+\n",
      "|label|        prediction|\n",
      "+-----+------------------+\n",
      "| 16.0|1.6553427500989315|\n",
      "| 24.0|10.954350390882297|\n",
      "| 24.6|11.712100273924944|\n",
      "| 14.0|10.912847777325894|\n",
      "| 21.4|  11.1167697235563|\n",
      "| 22.6|11.417486029895562|\n",
      "| 23.8|12.847282037416234|\n",
      "| 19.8| 8.040327182680802|\n",
      "| 22.4|12.832230407539946|\n",
      "| 18.2| 9.017316950496369|\n",
      "+-----+------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# 1. Define the model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# 2. Train the model\n",
    "print(\"Training Linear Regression model...\")\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# 3. Make predictions on the test data\n",
    "print(\"Evaluating model on test data...\")\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "\n",
    "# 4. Evaluate the model\n",
    "# We'll use RMSE (Root Mean Squared Error)\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(lr_predictions)\n",
    "print(f\"\\n--- Linear Regression Results ---\")\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data = {rmse}\")\n",
    "\n",
    "# We can also check R-squared (R2)\n",
    "r2_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"r2\"\n",
    ")\n",
    "r2 = r2_evaluator.evaluate(lr_predictions)\n",
    "print(f\"R-squared (R2) on test data = {r2}\")\n",
    "\n",
    "# Look at some predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "lr_predictions.select(\"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df863568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 265:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) for Linear Regression = 3.6152530887644323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate MAE using the existing predictions\n",
    "mae = evaluator.evaluate(lr_predictions, {evaluator.metricName: \"mae\"})\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE) for Linear Regression = {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a2cd4d",
   "metadata": {},
   "source": [
    "### Second baseline model: Gradient-Boosted Tree (GBT) Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee1b4866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient-Boosted Tree (GBT) model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/31 14:07:46 WARN MemoryStore: Not enough space to cache rdd_88_0 in memory! (computed 1560.1 MiB so far)\n",
      "25/10/31 14:07:47 WARN MemoryStore: Not enough space to cache rdd_88_0 in memory! (computed 1560.1 MiB so far)\n",
      "25/10/31 14:07:53 WARN MemoryStore: Not enough space to cache rdd_88_0 in memory! (computed 1560.1 MiB so far)\n",
      "25/10/31 14:07:59 WARN MemoryStore: Not enough space to cache rdd_88_0 in memory! (computed 1560.1 MiB so far)\n",
      "25/10/31 14:08:02 WARN MemoryStore: Not enough space to cache rdd_185_0 in memory! (computed 564.5 MiB so far)\n",
      "25/10/31 14:08:02 WARN BlockManager: Persisting block rdd_185_0 to disk instead.\n",
      "25/10/31 14:08:20 WARN MemoryStore: Not enough space to cache rdd_205_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:08:20 WARN BlockManager: Persisting block rdd_205_0 to disk instead.\n",
      "25/10/31 14:08:24 WARN MemoryStore: Not enough space to cache rdd_205_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:08:25 WARN MemoryStore: Not enough space to cache rdd_208_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:08:25 WARN BlockManager: Persisting block rdd_208_0 to disk instead.\n",
      "25/10/31 14:08:37 WARN MemoryStore: Not enough space to cache rdd_205_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:08:37 WARN MemoryStore: Not enough space to cache rdd_227_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:08:37 WARN BlockManager: Persisting block rdd_227_0 to disk instead.\n",
      "25/10/31 14:08:42 WARN MemoryStore: Not enough space to cache rdd_227_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:08:42 WARN MemoryStore: Not enough space to cache rdd_230_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:08:42 WARN BlockManager: Persisting block rdd_230_0 to disk instead.\n",
      "25/10/31 14:08:54 WARN MemoryStore: Not enough space to cache rdd_227_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:08:54 WARN MemoryStore: Not enough space to cache rdd_249_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:08:54 WARN BlockManager: Persisting block rdd_249_0 to disk instead.\n",
      "25/10/31 14:09:00 WARN MemoryStore: Not enough space to cache rdd_249_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:09:00 WARN MemoryStore: Not enough space to cache rdd_252_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:09:00 WARN BlockManager: Persisting block rdd_252_0 to disk instead.\n",
      "25/10/31 14:09:12 WARN MemoryStore: Not enough space to cache rdd_249_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:09:13 WARN MemoryStore: Not enough space to cache rdd_271_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:09:13 WARN BlockManager: Persisting block rdd_271_0 to disk instead.\n",
      "25/10/31 14:09:18 WARN MemoryStore: Not enough space to cache rdd_271_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:09:18 WARN MemoryStore: Not enough space to cache rdd_274_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:09:18 WARN BlockManager: Persisting block rdd_274_0 to disk instead.\n",
      "25/10/31 14:09:30 WARN MemoryStore: Not enough space to cache rdd_271_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:09:30 WARN MemoryStore: Not enough space to cache rdd_293_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:09:30 WARN BlockManager: Persisting block rdd_293_0 to disk instead.\n",
      "25/10/31 14:09:36 WARN MemoryStore: Not enough space to cache rdd_293_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:09:36 WARN MemoryStore: Not enough space to cache rdd_296_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:09:36 WARN BlockManager: Persisting block rdd_296_0 to disk instead.\n",
      "25/10/31 14:09:48 WARN MemoryStore: Not enough space to cache rdd_293_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:09:48 WARN MemoryStore: Not enough space to cache rdd_315_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:09:48 WARN BlockManager: Persisting block rdd_315_0 to disk instead.\n",
      "25/10/31 14:09:54 WARN MemoryStore: Not enough space to cache rdd_315_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:09:54 WARN MemoryStore: Not enough space to cache rdd_318_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:09:54 WARN BlockManager: Persisting block rdd_318_0 to disk instead.\n",
      "25/10/31 14:10:06 WARN MemoryStore: Not enough space to cache rdd_315_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:10:06 WARN MemoryStore: Not enough space to cache rdd_337_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:10:06 WARN BlockManager: Persisting block rdd_337_0 to disk instead.\n",
      "25/10/31 14:10:11 WARN MemoryStore: Not enough space to cache rdd_337_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:10:11 WARN MemoryStore: Not enough space to cache rdd_340_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:10:11 WARN BlockManager: Persisting block rdd_340_0 to disk instead.\n",
      "25/10/31 14:10:23 WARN MemoryStore: Not enough space to cache rdd_337_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:10:24 WARN MemoryStore: Not enough space to cache rdd_359_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:10:24 WARN BlockManager: Persisting block rdd_359_0 to disk instead.\n",
      "25/10/31 14:10:29 WARN MemoryStore: Not enough space to cache rdd_359_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:10:29 WARN MemoryStore: Not enough space to cache rdd_362_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:10:29 WARN BlockManager: Persisting block rdd_362_0 to disk instead.\n",
      "25/10/31 14:10:42 WARN MemoryStore: Not enough space to cache rdd_359_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:10:42 WARN MemoryStore: Not enough space to cache rdd_381_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:10:42 WARN BlockManager: Persisting block rdd_381_0 to disk instead.\n",
      "25/10/31 14:10:47 WARN MemoryStore: Not enough space to cache rdd_381_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:10:47 WARN MemoryStore: Not enough space to cache rdd_384_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:10:47 WARN BlockManager: Persisting block rdd_384_0 to disk instead.\n",
      "25/10/31 14:10:59 WARN MemoryStore: Not enough space to cache rdd_381_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:10:59 WARN MemoryStore: Not enough space to cache rdd_403_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:10:59 WARN BlockManager: Persisting block rdd_403_0 to disk instead.\n",
      "25/10/31 14:11:05 WARN MemoryStore: Not enough space to cache rdd_403_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:11:05 WARN MemoryStore: Not enough space to cache rdd_406_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:11:05 WARN BlockManager: Persisting block rdd_406_0 to disk instead.\n",
      "25/10/31 14:11:17 WARN MemoryStore: Not enough space to cache rdd_403_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:11:18 WARN MemoryStore: Not enough space to cache rdd_425_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:11:18 WARN BlockManager: Persisting block rdd_425_0 to disk instead.\n",
      "25/10/31 14:11:23 WARN MemoryStore: Not enough space to cache rdd_425_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:11:23 WARN MemoryStore: Not enough space to cache rdd_428_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:11:23 WARN BlockManager: Persisting block rdd_428_0 to disk instead.\n",
      "25/10/31 14:11:35 WARN MemoryStore: Not enough space to cache rdd_425_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:11:35 WARN MemoryStore: Not enough space to cache rdd_447_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:11:35 WARN BlockManager: Persisting block rdd_447_0 to disk instead.\n",
      "25/10/31 14:11:41 WARN MemoryStore: Not enough space to cache rdd_447_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:11:41 WARN MemoryStore: Not enough space to cache rdd_450_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:11:41 WARN BlockManager: Persisting block rdd_450_0 to disk instead.\n",
      "25/10/31 14:11:53 WARN MemoryStore: Not enough space to cache rdd_447_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:11:53 WARN MemoryStore: Not enough space to cache rdd_469_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:11:53 WARN BlockManager: Persisting block rdd_469_0 to disk instead.\n",
      "25/10/31 14:11:58 WARN MemoryStore: Not enough space to cache rdd_469_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:11:58 WARN MemoryStore: Not enough space to cache rdd_472_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:11:58 WARN BlockManager: Persisting block rdd_472_0 to disk instead.\n",
      "25/10/31 14:12:11 WARN MemoryStore: Not enough space to cache rdd_469_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:12:11 WARN MemoryStore: Not enough space to cache rdd_491_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:12:11 WARN BlockManager: Persisting block rdd_491_0 to disk instead.\n",
      "25/10/31 14:12:16 WARN MemoryStore: Not enough space to cache rdd_491_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:12:16 WARN MemoryStore: Not enough space to cache rdd_494_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:12:16 WARN BlockManager: Persisting block rdd_494_0 to disk instead.\n",
      "25/10/31 14:12:29 WARN MemoryStore: Not enough space to cache rdd_491_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:12:29 WARN MemoryStore: Not enough space to cache rdd_513_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:12:29 WARN BlockManager: Persisting block rdd_513_0 to disk instead.\n",
      "25/10/31 14:12:34 WARN MemoryStore: Not enough space to cache rdd_513_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:12:34 WARN MemoryStore: Not enough space to cache rdd_516_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:12:34 WARN BlockManager: Persisting block rdd_516_0 to disk instead.\n",
      "25/10/31 14:12:46 WARN MemoryStore: Not enough space to cache rdd_513_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:12:46 WARN MemoryStore: Not enough space to cache rdd_535_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:12:46 WARN BlockManager: Persisting block rdd_535_0 to disk instead.\n",
      "25/10/31 14:12:52 WARN MemoryStore: Not enough space to cache rdd_535_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:12:52 WARN MemoryStore: Not enough space to cache rdd_538_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:12:52 WARN BlockManager: Persisting block rdd_538_0 to disk instead.\n",
      "25/10/31 14:13:04 WARN MemoryStore: Not enough space to cache rdd_535_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:13:04 WARN MemoryStore: Not enough space to cache rdd_557_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:13:04 WARN BlockManager: Persisting block rdd_557_0 to disk instead.\n",
      "25/10/31 14:13:09 WARN MemoryStore: Not enough space to cache rdd_557_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:13:10 WARN MemoryStore: Not enough space to cache rdd_560_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:13:10 WARN BlockManager: Persisting block rdd_560_0 to disk instead.\n",
      "25/10/31 14:13:22 WARN MemoryStore: Not enough space to cache rdd_557_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:13:22 WARN MemoryStore: Not enough space to cache rdd_579_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:13:22 WARN BlockManager: Persisting block rdd_579_0 to disk instead.\n",
      "25/10/31 14:13:27 WARN MemoryStore: Not enough space to cache rdd_579_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:13:27 WARN MemoryStore: Not enough space to cache rdd_582_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:13:27 WARN BlockManager: Persisting block rdd_582_0 to disk instead.\n",
      "25/10/31 14:13:39 WARN MemoryStore: Not enough space to cache rdd_579_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:13:39 WARN MemoryStore: Not enough space to cache rdd_601_0 in memory! (computed 104.0 MiB so far)\n",
      "25/10/31 14:13:39 WARN BlockManager: Persisting block rdd_601_0 to disk instead.\n",
      "25/10/31 14:13:44 WARN MemoryStore: Not enough space to cache rdd_601_0 in memory! (computed 624.0 MiB so far)\n",
      "25/10/31 14:13:44 WARN MemoryStore: Not enough space to cache rdd_604_0 in memory! (computed 99.2 MiB so far)\n",
      "25/10/31 14:13:44 WARN BlockManager: Persisting block rdd_604_0 to disk instead.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on test data...\n",
      "\n",
      "--- GBT Regressor Results ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 3.9701468978091836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 246:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (R2) on test data = 0.9000404116751486\n",
      "\n",
      "Sample predictions:\n",
      "+-----+------------------+\n",
      "|label|        prediction|\n",
      "+-----+------------------+\n",
      "| 16.0| 8.957869265136855|\n",
      "| 24.0|  16.1846702747226|\n",
      "| 24.6|14.936362538571226|\n",
      "| 14.0|15.406506544078244|\n",
      "| 21.4| 15.73878241677836|\n",
      "| 22.6| 15.73878241677836|\n",
      "| 23.8|15.346555738802495|\n",
      "| 19.8|14.397397344044641|\n",
      "| 22.4|19.465942939900316|\n",
      "| 18.2| 18.47062185130404|\n",
      "+-----+------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "# 1. Define the model\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# 2. Train the model\n",
    "print(\"Training Gradient-Boosted Tree (GBT) model...\")\n",
    "gbt_model = gbt.fit(train_data)\n",
    "\n",
    "# 3. Make predictions on the test data\n",
    "print(\"Evaluating model on test data...\")\n",
    "gbt_predictions = gbt_model.transform(test_data)\n",
    "\n",
    "# 4. Evaluate the model (using the same 'rmse' evaluator from before)\n",
    "print(\"\\n--- GBT Regressor Results ---\")\n",
    "rmse = evaluator.evaluate(gbt_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data = {rmse}\")\n",
    "\n",
    "# We can also check R-squared\n",
    "r2 = evaluator.evaluate(gbt_predictions, {evaluator.metricName: \"r2\"})\n",
    "print(f\"R-squared (R2) on test data = {r2}\")\n",
    "\n",
    "# Look at some predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "gbt_predictions.select(\"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d36544d",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f2538f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the GBT model...\n",
      "Model successfully saved to: gbt_model_v1\n"
     ]
    }
   ],
   "source": [
    "# 1. Make sure 'gbt_model' is the variable holding your trained GBT model\n",
    "#    (The one from 'gbt_model = gbt.fit(train_data)')\n",
    "\n",
    "print(\"Saving the GBT model...\")\n",
    "model_path = \"gbt_model_v1\" # This will be a folder name\n",
    "gbt_model.save(model_path)\n",
    "\n",
    "print(f\"Model successfully saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cb658f",
   "metadata": {},
   "source": [
    "### Model: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c86df05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest Regressor model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/31 14:14:02 WARN MemoryStore: Not enough space to cache rdd_88_0 in memory! (computed 1560.1 MiB so far)\n",
      "25/10/31 14:14:03 WARN MemoryStore: Not enough space to cache rdd_88_0 in memory! (computed 1560.1 MiB so far)\n",
      "25/10/31 14:14:09 WARN MemoryStore: Not enough space to cache rdd_88_0 in memory! (computed 1560.1 MiB so far)\n",
      "25/10/31 14:14:15 WARN MemoryStore: Not enough space to cache rdd_88_0 in memory! (computed 1560.1 MiB so far)\n",
      "25/10/31 14:14:17 WARN MemoryStore: Not enough space to cache rdd_665_0 in memory! (computed 526.4 MiB so far)\n",
      "25/10/31 14:14:17 WARN BlockManager: Persisting block rdd_665_0 to disk instead.\n",
      "25/10/31 14:14:47 WARN MemoryStore: Not enough space to cache rdd_665_0 in memory! (computed 1776.6 MiB so far)\n",
      "25/10/31 14:15:02 WARN MemoryStore: Not enough space to cache rdd_665_0 in memory! (computed 1776.6 MiB so far)\n",
      "25/10/31 14:15:20 WARN MemoryStore: Not enough space to cache rdd_665_0 in memory! (computed 1776.6 MiB so far)\n",
      "25/10/31 14:15:41 WARN MemoryStore: Not enough space to cache rdd_665_0 in memory! (computed 1776.6 MiB so far)\n",
      "25/10/31 14:16:06 WARN MemoryStore: Not enough space to cache rdd_665_0 in memory! (computed 1776.6 MiB so far)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on test data...\n",
      "\n",
      "--- Random Forest Regressor Results ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 4.970377408842473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 263:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (R2) on test data = 0.8433284861801813\n",
      "\n",
      "Sample predictions:\n",
      "+-----+------------------+\n",
      "|label|        prediction|\n",
      "+-----+------------------+\n",
      "| 16.0| 8.382791808895158|\n",
      "| 24.0|16.624661266238093|\n",
      "| 24.6|18.125906575142995|\n",
      "| 14.0|18.203216175948437|\n",
      "| 21.4|  16.3187749514485|\n",
      "| 22.6|17.299505311611078|\n",
      "| 23.8|18.509102490738034|\n",
      "| 19.8|16.901954603725823|\n",
      "| 22.4| 16.64513671916166|\n",
      "| 18.2|  18.5076429098647|\n",
      "+-----+------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# 1. Define the model\n",
    "# Using the same evaluator as before (RMSE)\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# 2. Train the model\n",
    "print(\"Training Random Forest Regressor model...\")\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# 3. Make predictions on the test data\n",
    "print(\"Evaluating model on test data...\")\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "\n",
    "# 4. Evaluate the model\n",
    "print(\"\\n--- Random Forest Regressor Results ---\")\n",
    "rmse = evaluator.evaluate(rf_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data = {rmse}\")\n",
    "\n",
    "# We can also check R-squared\n",
    "r2 = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"r2\"})\n",
    "print(f\"R-squared (R2) on test data = {r2}\")\n",
    "\n",
    "# Look at some predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "rf_predictions.select(\"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f12d0",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfe43c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the Random Forest model...\n",
      "Model successfully saved to: rf_model_v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/31 16:23:10 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 492182 ms exceeds timeout 120000 ms\n",
      "25/10/31 16:23:10 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "25/10/31 16:23:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:23:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:23:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:23:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:23:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:23:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:23:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:23:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:23:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:23:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:24:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:24:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:24:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:24:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:24:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:24:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:24:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:24:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:24:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:24:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:25:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:25:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:25:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:25:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:26:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:26:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:26:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:26:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:26:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:26:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:26:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:26:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:26:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:26:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:26:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:26:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:27:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:27:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:27:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "25/10/31 16:27:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "25/10/31 16:27:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:27:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:27:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:27:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:27:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:27:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:27:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:27:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:28:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:28:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:28:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:28:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:28:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:28:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:28:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:28:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:28:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:28:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:28:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:28:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:29:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:29:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:29:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:29:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:29:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:29:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:29:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:29:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:29:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:29:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:29:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:29:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:30:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:30:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:30:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:30:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:30:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:30:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:30:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:30:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:30:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:30:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:30:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:30:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:31:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:31:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:31:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:31:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:31:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:31:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:31:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "25/10/31 16:31:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "25/10/31 16:31:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:31:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:31:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:31:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:32:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:32:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:32:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:32:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:32:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:32:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:32:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:32:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:32:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:32:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:33:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:33:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:33:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:33:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:33:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:33:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:33:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:33:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:33:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:33:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:33:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:33:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.31.115.162:51752\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/31 16:33:56 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "# 1. Make sure 'rf_model' is the variable holding your trained Random Forest model\n",
    "#    (The one from 'rf_model = rf.fit(train_data)')\n",
    "\n",
    "print(\"Saving the Random Forest model...\")\n",
    "rf_model_path = \"rf_model_v1\" # This will be a folder name\n",
    "rf_model.save(rf_model_path)\n",
    "\n",
    "print(f\"Model successfully saved to: {rf_model_path}\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "178dc6c2",
   "metadata": {},
   "source": [
    "Here's a markdown table summarizing the results of your models trained on the full feature set.\n",
    "\n",
    " Model Performance Comparison (All Features)\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f3f2a9",
   "metadata": {},
   "source": [
    "Why Not Use AdaBoost?\n",
    "\n",
    "While AdaBoost is a well-known boosting algorithm, it was not used in this project for two primary reasons:\n",
    "\n",
    "    Library Limitation: pyspark.ml (Spark's machine learning library) does not include an AdaBoostRegressor. It only provides AdaBoostClassifier, which cannot be used for a regression problem (predicting a continuous value like temperature).\n",
    "\n",
    "    GBT is the Modern Successor: The GBTRegressor (Gradient-Boosted Tree) model that we are already using is the modern, more powerful, and more flexible evolution of the same boosting concept that AdaBoost pioneered. GBT is the industry-standard choice for high-performance regression on tabular data.\n",
    "\n",
    "In short, we are already using a more powerful version of a boosting model, and the specific regression version of AdaBoost isn't available in Spark's ML library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
